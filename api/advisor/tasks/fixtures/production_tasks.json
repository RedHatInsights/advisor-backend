[
  {
    "model": "tasks.Task",
    "pk": 1,
    "fields": {
      "slug": "ping",
      "title": "Run the ansible ping module",
      "description": "This task runs the ansible ping module on the given system. This is a simple action that allows the testing of the entire task pipeline without modifying the system.",
      "active": true,
      "type": "A",
      "filters": [
        "rhel"
      ],
      "filter_message": "Eligible systems for this task include RHEL systems that are registered via RHC",
      "publish_date": "2022-05-18T00:00:00Z",
      "playbook": "- name: ping\n  hosts: localhost\n  vars:\n    insights_signature_exclude: /hosts,/vars/insights_signature\n    insights_signature: !!binary |\n      TFMwdExTMUNSVWRKVGlCUVIxQWdVMGxIVGtGVVZWSkZMUzB0TFMwS1ZtVnljMmx2YmpvZ1IyNTFV\n      RWNnZGpFS0NtbFJTV05DUVVGQ1EwRkJSMEpSU20xWlkxZEZRVUZ2U2tWTmRuYzFPRVFyYWpWd1Rq\n      RnFRVkFyZDFjdmRVaHFaMFYyTVdjeWMxWTNWREowWW1WaFdUY0tUSGRHTkd0NWRXcDBPRGxyVW10\n      NFFUZFZMMHhYWW5kSWNsVldXWEppZEc5TGNtOVZhRWh2TmpSa1NHOVdaVXBTVjNBNFYzVXZORVpJ\n      V2toNk9IbDRXUXA1WVN0QldEQjZTbkV5T0RGVVYzZG5XbVI0UkdaMFRsQkpTalIyU1hoMlZXSnNN\n      bVp4WTA5TldHUjFXSE01YWxSRWVIUTBhbWxaU3k4ME5HbGpOeTlSQ25kUFNsaHpNbGQzT1RSUFVY\n      UjRSMlo2UkVSdFEyRnVTMVV6UjJ0Ukx5ODJUMEZTZERkUk1WTjNSVWR4U0dac1NWRlFTVnBOZW5o\n      RE5FNW1TMWRGU0VrS2IwTTNSRVoyTUZWbVVHRnhORkJPTWxWUGVIVTNjbWx0UldKSFVtZHFXVmgw\n      Um5CNmNrUmpSMVpITVhwQ1ZHTkxaSEp1YlVsdE0yNU1WVmRwYVRONVdBcHRUVE0wUkZZcmQxRnhR\n      bmMzV1hkc1UzSkZLek14WmtjclZYUTFVVWhFTVZaQmFVbHFlbEZWWVM5S1MwdG5Va2xsVFd4b2F6\n      TTFWVEl4Y0ZsTFVXdGFDa2RuYzJFMVYzUXdjbFp4VjIxcldYQk5hVTloY0RsM01ESnFhRVZOYlho\n      bVNuVm9NVGRFTnk5NmQxVnpZMjlZWkc5MU1HRnFNV0pHY1RSV1V6VnJRMDBLU3pOV0t6SXpTR3RT\n      TkRSaWVHRnNRbTFxYjNZeFVsbzFjV04wVGs0NE16Wk9WbVU1VHpGMVdWTTNSWFZHWTJKTFZ6TmFO\n      WEZaYTNKa2R6Vm9aMlpDTmdwNFdETlRNMVZWYUhOV1QyTjVSRnBvVFdGMFVtdzBSRXRvTkhORU1X\n      NXBNa0ZMUzJsVVVXTjBTRU00VjJoQk4zVk9OVGwwVUZwcVdubGtjMGxJTjFCbkNtTmhabk5KYlZB\n      clUzSnVRMHhyU1ZsQlZWVnRlSEYyVURCYU1UUkRTMkZzZEdkMVdrbEpkR2hCWlU1dGJ6VTBhbEZC\n      UTJaRVdHMHlVMGxUVFdzMU1FVUtTa3hoY20xelJtRlBZU3RMVDJkUldIZHBlVE53YlRkWmIxTndS\n      bUVyVjAxbFYwUnJha2hwUkZOeE1IcE9UVk5vWVc5TlpWSjJORkF5WXpWUFNGVkNhQXBwVEZab1Fs\n      cERNRmgwV2pkQmNrVmxabGRhTmdvOVVqUlpkUW90TFMwdExVVk9SQ0JRUjFBZ1UwbEhUa0ZVVlZK\n      RkxTMHRMUzBL\n  tasks:\n    - name: ping\n      ansible.builtin.ping:\n      register: ping_output\n      ignore_errors: true\n\n    - name: Set result\n      ansible.builtin.set_fact:\n        task_results:\n          report: \"{{ping_output | default('')}}\"\n          message: \"{{ping_output.ping | default('Error performing ping task')}}\"\n          alert: \"{{ping_output.failed | default('true')}}\"\n\n    - name: Print Task Result\n      ansible.builtin.debug:\n        var: task_results\n"
    }
  },
  {
    "model": "tasks.Task",
    "pk": 2,
    "fields": {
      "slug": "insights-client",
      "title": "Run the insights-client",
      "description": "This task runs the command \"insights-client\" on the system. If the system is registered with insights, the system will do a standard insights-client collection and upload.",
      "active": true,
      "type": "A",
      "filters": [
          "rhel"
      ],
      "filter_message": "Eligible systems for this task include RHEL systems that are registered via RHC",
      "publish_date": "2022-05-18T00:00:00Z",
      "playbook": "- name: run insights\n  hosts: localhost\n  become: true\n  gather_facts: false\n  vars:\n    insights_signature_exclude: /hosts,/vars/insights_signature,/vars/content_vars\n    insights_signature: !!binary |\n      TFMwdExTMUNSVWRKVGlCUVIxQWdVMGxIVGtGVVZWSkZMUzB0TFMwS1ZtVnljMmx2YmpvZ1IyNTFV\n      RWNnZGpFS0NtbFJTV05DUVVGQ1EwRkJSMEpSU200NE1UaG1RVUZ2U2tWTmRuYzFPRVFyYWpWd1Rq\n      WXljMUF2TWs1alpIaE1XbGswTW1jeWNtUnFOVWR1YmxaelVVRUtXRGRrTVZSNldWcEdaWFp0UTFS\n      VFJrSTRNVzlMVW1sRGRXUlVSMVY0UTJ3NWNrOVNabTlMVjNwek0xWkVaV3g0VWpCdWVFaGpXVUV6\n      WmtOR1MxUlRUd3BhT1hsRGVtSkpSRk5yZDA1SGMwTnliRlozYjNkeU1tRXhkVlJtVWxaRFZYUmha\n      MHh0TlRJeWRXUnJlVGc1ZERWeGJHWTVZVUZKVVZOSFRuTkRhRE5FQ25OdU4wVlpPRlUyU21WR1FX\n      RTRMM1pIZDFsVVFVVnFSV3B5V200M2FrczVRMkZUU2toUFdtVk5Za3hFT0hVeE0yazVXSGxvYUVW\n      b1ZHdFVhRk5GV20wS1IxZFBVMGRoVUM5Q1JWRm9URVZVZFU0MlNVbDBVbTVYUldSWVltOVNaV2R0\n      Y0dGb1JIaHBTbmR0S3pkUE1UaHhWV1F6YjI1R1pUWjRXR05CZUZaMVJBb3JUMk5NUVhSRE5tRlNT\n      MjFPV201MmFGQlFORmhzUkhodVYzWk1OVkpzTkVsd2FTdHdUbE5HZGs0eU1FWk9UeXRLTmtoMVdE\n      ZGpSVnBWT0RWalVuaENDbXRoUkRaR1dtRkdXR3htUldWVFRUWlFhSE5NZWpBd09UUmFNMk5SU1V4\n      SWFrRlRjakJGZEhCeVdVZFllRmRqVjBkM1NWTktWMDVKTm1OVVNsRk5TVWNLUld3NFUyRnpTazFY\n      WW1sWGVFbHRWR3AwYURKc1luQnJSV3BsVjBSRGRsaFVjV1pzTnpVd01rbzFSR2htVVhvdk16WktN\n      MHBVYVVwU09GTnlMMGd6U0FwSGQwUmlkRk5tU0dsdFRHcGxaalpGU2psbUx6TTNaRkJFZUdwbU9X\n      aGlaSGR1ZVdaSEszVnRRMGN5TUdjeVF6SktTV3RXT1RWTE1XRjROMGhxWlc5RkNtbE9haTlKWlZk\n      aFlVd3ZTbWRFUlhCcFkyZENXVk54ZFVKdldtMVZNVkJuU1doblFrNTZVV3c1WlZGTGFEWXZXRFp3\n      UVZRMlJIcDBhRXROV0ZaWFpGVUtVWGsyVFZOS2VGZHRUVU4yUVVkb1MyMHpkRTVVZDBGS1RsZFNR\n      bTVIVFhWa2NUWnVhamRWV21ablVsTm9lbkphT0RkR1dtVkxibUlyVUV4cFJWZHlPQW92Y1RGeVVY\n      SmFiWEZHVWpaWlRrRndNalZOWkFvOVRVbzBPUW90TFMwdExVVk9SQ0JRUjFBZ1UwbEhUa0ZVVlZK\n      RkxTMHRMUzBL\n    insights_client_command: insights-client\n    content_vars:\n# insight-client switches that may be set via task parameters\n      collector: \"None\"\n      show_results: \"False\"\n      status: \"False\"\n      test_connection: \"False\"\n      verbose: \"False\"\n      keep_archive: \"False\"\n\n  tasks:\n    - name: Add --collector switch if collector variable is not none\n      set_fact:\n        insights_client_command: \"{{ insights_client_command }} --collector {{ content_vars.collector }}\"\n      when: content_vars.collector is defined and content_vars.collector not in [\"None\", \"none\", \"\", None]\n\n    - name: Add --show-results switch if show_results variable is true\n      set_fact:\n        insights_client_command: \"{{ insights_client_command }} --show-results\"\n      when: content_vars.show_results is defined and content_vars.show_results in [\"True\", \"true\", True]\n\n    - name: Add --status switch if status variable is true\n      set_fact:\n        insights_client_command: \"{{ insights_client_command }} --status\"\n      when: content_vars.status is defined and content_vars.status in [\"True\", \"true\", True]\n\n    - name: Add --test-connection switch if test_connection variable is true\n      set_fact:\n        insights_client_command: \"{{ insights_client_command }} --test-connection\"\n      when: content_vars.test_connection is defined and content_vars.test_connection in [\"True\", \"true\", True]\n\n    - name: Add --verbose switch if verbose variable is true\n      set_fact:\n        insights_client_command: \"{{ insights_client_command }} --verbose\"\n      when: content_vars.verbose is defined and content_vars.verbose in [\"True\", \"true\", True]\n\n    - name: Add --keep-archive switch if keep_archive is true\n      set_fact:\n        insights_client_command: \"{{ insights_client_command }} --keep-archive\"\n      when: content_vars.keep_archive is defined and content_vars.keep_archive in [\"True\", \"true\", True]\n\n    - name: run insights\n      shell: \"NO_COLOR=1 {{ insights_client_command }} 2>&1\"\n      register: insights_client_output\n      no_log: true\n      ignore_errors: true\n\n    - when: insights_client_output.rc != 0\n      name: Set result for failure\n      ansible.builtin.set_fact:\n        task_results:\n          report: \"{{insights_client_output.stdout}}\\n{{insights_client_output.stderr}}\"\n          message: \"insights-client failed. Expand for details.\"\n          alert: true\n\n    - when: task_results is not defined\n      name: Set result for completed successfully\n      ansible.builtin.set_fact:\n        task_results:\n          report: \"{{insights_client_output}}\"\n          message: \"{{insights_client_output.stdout}}\"\n          alert: false\n\n    - name: Print Task Result\n      ansible.builtin.debug:\n        var: task_results\n"
    }
  },
  {
    "model": "tasks.Task",
    "pk": 3,
    "fields": {
      "slug": "leapp-preupgrade",
      "title": "Pre-upgrade analysis for in-place upgrade from RHEL 8",
      "description": "You can run the pre-upgrade analysis task on connected RHEL 8 systems. This task identifies potential issues and provides you with guidance on how to remediate these issues before you upgrade. \n\nThis task supports RHEL 8. Additional documentation to complete the upgrade experience can be found at [Upgrading from RHEL 8 to RHEL 9](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/upgrading_from_rhel_8_to_rhel_9/index#planning-an-upgrade_upgrading-from-rhel-8-to-rhel-9)",
      "active": true,
      "type": "A",
      "filters": [
        "rhel",
        "os_v8"
      ],
      "filter_message": "Eligible systems include RHEL 8 systems connected to console.redhat.com with rhc, or Satellite with Cloud Connector",
      "publish_date": "2022-10-05T00:00:00Z",
      "playbook": "- name: task for leapp pre-upgrade assessment\n  hosts: localhost\n  become: true\n  vars:\n    rhui_packages:\n      rhel7:\n        - src_pkg: rh-amazon-rhui-client\n          leapp_pkg: leapp-rhui-aws\n        - src_pkg: rh-amazon-rhui-client-sap-bundle\n          leapp_pkg: leapp-rhui-aws-sap-e4s\n        - src_pkg: rhui-azure-rhel7\n          leapp_pkg: leapp-rhui-azure\n        - src_pkg: rhui-azure-rhel7-base-sap-apps\n          leapp_pkg: leapp-rhui-azure-sap\n        - src_pkg: rhui-azure-rhel7-base-sap-ha\n          leapp_pkg: leapp-rhui-azure-sap\n        - src_pkg: google-rhui-client-rhel7\n          leapp_pkg: leapp-rhui-google\n        - src_pkg: google-rhui-client-rhel79-sap\n          leapp_pkg: leapp-rhui-google-sap\n      rhel8:\n        - src_pkg: rh-amazon-rhui-client\n          leapp_pkg: leapp-rhui-aws\n        - src_pkg: rh-amazon-rhui-client-sap-bundle-e4s\n          leapp_pkg: leapp-rhui-aws-sap-e4s\n        - src_pkg: rhui-azure-rhel8\n          leapp_pkg: leapp-rhui-azure\n        - src_pkg: rhui-azure-rhel8-eus\n          leapp_pkg: leapp-rhui-azure-eus\n        - src_pkg: rhui-azure-rhel8-sap-ha\n          leapp_pkg: leapp-rhui-azure-sap\n        - src_pkg: rhui-azure-rhel8-sapapps\n          leapp_pkg: leapp-rhui-azure-sap\n        - src_pkg: google-rhui-client-rhel8\n          leapp_pkg: leapp-rhui-google\n        - src_pkg: google-rhui-client-rhel8-sap\n          leapp_pkg: leapp-rhui-google-sap\n    preupgrade_command: '/usr/bin/leapp preupgrade --report-schema=1.2.0'\n    no_rhsm: false\n    insights_signature_exclude: /hosts,/vars/insights_signature\n    insights_signature: !!binary |\n      TFMwdExTMUNSVWRKVGlCUVIxQWdVMGxIVGtGVVZWSkZMUzB0TFMwS1ZtVnljMmx2YmpvZ1IyNTFV\n      RWNnZGpFS0NtbFJTV05DUVVGQ1EwRkJSMEpSU214NWEzWlVRVUZ2U2tWTmRuYzFPRVFyYWpWd1Rq\n      WndORkF2TW1rNGEzVkdUMWhtY1c4ek1EWXpUVnBtVUVOdlVuUUtVR2Q2ZGpkb1pHaDJlakVyVG1w\n      bVRqbHBLM2RwVjJkRFZ6TlpOSFpRU1hwcFRubFRVV2hOT1dSMGVtMDFSM016TkVGTFYwMHplbE1y\n      YkdOamIxZDFSZ3BuWjBOb1ZtczVTRlJIUkdKS1lrNDNSell2VTNnMGEwTlJVbmhUZUVOMVRtaFpN\n      a3hwVGxOVFQybFFjelZGVVRWR1dHRlFWVGhPU2xwclNVWnhNMm95Q25OTVVscG5la1EzYkZaU1NF\n      ZFFZVzFtYVVsT2RGVXdkSEYxUkhSM1ozcFRWV0ppVmxKQlRsRTVVRUY2YzJObFFXUjRNME5HT0ZK\n      dmNrVkNlakJrWjB3S1VYaHBkR2h4U0ZkdVpUaFdSVmRaT0dGcmVUbEZkV054YzFKMWNsUTRWMnB6\n      Vkd4a1dVTnROMW8xTDBod2FUazROWGxYWm1sdFNtMDBNREZYUzA1TU9BcENlbkl4Umk5ME4zSkxX\n      QzlZWkhodE5FZFNZMmhGYnk5cE5qaFRiVVI1YlVOV1duUlVUU3RZUm5GbU5VMUtaMnRsUzBKTUt6\n      ZGxlV1pLUkhSVU1IcEdDbTltU0hGWFlqZGtTSFJ3VUZreU5FbGhhUzh6WjBFeU16ZDRhMmNyYjBk\n      M2RFMUZkbkpaVGt4WVdscFdUVmhFTmtOdGMyRmxhVXRrVUdRMWF6ZDBkbG9LWlRaVFlrbEtTRzU1\n      UzI0dlRIWjBVM0JLUVRCTVIxbHhZMWczVGpONGNqTjBORzVRV1VOTlJVUXpaSGROTmxSSmFGRnFV\n      WFJJWm5CeFRGRndOVzUxVEFwclQwcE9aRlZ4ZEhKVlVsRldOVEZPTHpsMlJXRnBjR3d4VmxSMlNH\n      WldWeTlpTWpSa2RIa3ZUR2cyTHpsaVpsWm9OVUpXU0RSMFR5OURTSG8wWm5kc0NuQXZaR0l4WjBa\n      blVIb3liR050VUhOdGNXbHVOVzFaTDBNeldXZ3ZRa2RoWjBJM1MzTTRabkZGZUdaUWRrSlJkR2wy\n      Y1VSME5tVnhNalpNWkZScFNtTUtUV2QxVkVFM1pqUnRMeTgyTVRKQlZqbHhVVlU0TjBKUlNHYzBZ\n      MVpTUVZseFVWZGlaSFJ3V1V0ck9YcDZiM0ZWUTBndlVFOVNkMnNyZHl0bGFGRk5UZ28xVmxGa01u\n      Qk9iVXhUZEZsQlNqTlJjbVYyYUFvOVRGZGtNd290TFMwdExVVk9SQ0JRUjFBZ1UwbEhUa0ZVVlZK\n      RkxTMHRMUzBL\n  tasks:\n    - name: Exit for non-eligible releases\n      ansible.builtin.meta: end_host\n      when:\n        - ansible_distribution != 'Red Hat Enterprise Linux'\n        - ansible_distribution_major_version <= '6'\n        - ansible_distribution_major_version >= '9'\n\n    - name: Gather package facts\n      package_facts:\n        manager: auto\n\n    - name: Set rhui_packages_found to empty list\n      set_fact:\n        rhui_packages_found: []\n\n    - name: Do RHEL7 specific tasks\n      block:\n        - name: Install Leapp from RHEL 7 Extras\n          yum:\n            name: leapp-upgrade\n            state: latest\n            enablerepo: rhel-7-server-extras-rpms\n        - name: Determine if any RHUI packages are installed on RHEL 7\n          set_fact:\n            rhui_packages_found: \"{{ rhui_packages_found + [item] }}\"\n          loop: \"{{ rhui_packages.rhel7 }}\"\n          when: item.src_pkg in ansible_facts.packages.keys()\n      when: ansible_distribution_major_version == '7'\n\n    - name: Do RHEL8 specific tasks\n      block:\n        - name: Install Leapp on RHEL 8\n          dnf:\n            name: leapp-upgrade\n            state: latest\n        - name: Determine if any RHUI packages are installed on RHEL 8\n          set_fact:\n            rhui_packages_found: \"{{ rhui_packages_found + [item] }}\"\n          loop: \"{{ rhui_packages.rhel8 }}\"\n          when: item.src_pkg in ansible_facts.packages.keys()\n      when: ansible_distribution_major_version == '8'\n\n    - name: Determine --no-rhsm flag usage and do corresponding steps when rhsm cannot be used\n      block:\n        - name: Check if subscription-manager is installed\n          command: which subscription-manager\n          changed_when: false\n          failed_when: false\n          register: rhsm_installed_check\n\n        - name: Check if system has repositories available\n          ansible.builtin.command: \"subscription-manager repos --list-enabled\"\n          register: rhsm_repo_check\n          changed_when: false\n          failed_when: false\n          when: rhsm_installed_check is success\n\n        - name: Set rhsm_repo_check_fail if there are no available repositories through RHSM\n          set_fact:\n            rhsm_repo_check_fail: true\n          when:\n            - >\n              'This system has no repositories available through subscriptions.' in rhsm_repo_check.stdout_lines or\n              'Repositories disabled by configuration.' in rhsm_repo_check.stdout_lines\n\n        - name: Set no_rhsm flag to true if RHUI package are found AND (there are no available repositories OR subscription-manager is not installed)\n          set_fact:\n            no_rhsm: true\n          when:\n            - rhui_packages_found | length > 0\n            - rhsm_installed_check is failed or rhsm_repo_check_fail is defined\n\n        - name: Add --no-rhsm switch to leapp preupgrade command if no_rhsm flag is true\n          set_fact:\n            preupgrade_command: \"{{ preupgrade_command }} --no-rhsm\"\n          when: no_rhsm == true\n\n        - name: Install corresponding leapp_pkg for installed RHUI packages if no_rhsm flag is true\n          yum:\n            name: \"{{ item.leapp_pkg }}\"\n            state: latest\n          loop: \"{{ rhui_packages_found }}\"\n          when: no_rhsm == true\n\n    - name: Remove previous json report\n      ansible.builtin.file:\n        path: /var/log/leapp/leapp-report.json\n        state: absent\n\n    - name: Remove previous text report\n      ansible.builtin.file:\n        path: /var/log/leapp/leapp-report.txt\n        state: absent\n\n    - name: Execute leapp pre-upgrade\n      ansible.builtin.shell: \"{{ preupgrade_command }} || true\"\n      ignore_errors: true\n\n    - name: Process the findings of the pre-upgrade\n      block:\n        - name: Read json report\n          ansible.builtin.slurp:\n            src: '/var/log/leapp/leapp-report.json'\n          register: report_content_raw\n\n        - name: Read text report\n          ansible.builtin.slurp:\n            src: '/var/log/leapp/leapp-report.txt'\n          register: report_content_txt_raw\n\n        - name: Set report fact\n          ansible.builtin.set_fact:\n            report_content: \"{{ report_content_raw.content | b64decode }}\"\n\n        - name: Set total problems count\n          ansible.builtin.set_fact:\n            total_problems_count: \"{{ report_content.entries | length }}\"\n\n        - name: Set inhibitor count\n          ansible.builtin.set_fact:\n            inhibitor_count: \"{{ report_content.entries | selectattr('groups', 'defined') | selectattr('groups', 'contains', 'inhibitor') | list | length }}\"\n\n        - name: Set errors count\n          ansible.builtin.set_fact:\n            error_count: \"{{ report_content.entries | selectattr('groups', 'defined') | selectattr('groups', 'contains', 'error') | list | length }}\"\n\n        - name: Init new empty entries for edited severity\n          ansible.builtin.set_fact:\n            report_content_edited: >-\n              {{\n                {\n                  \"entries\": []\n                }\n              }}\n\n        - name: Transform severities in leapp report to distinguish errors and inhibitors from other high risks entries\n          set_fact:\n            report_content_edited: >-\n              {{\n                report_content_edited | combine(\n                  {\n                    \"entries\": report_content_edited.entries | default([]) +\n                      [\n                        entry | combine(\n                          {\"severity\": \"inhibitor\"} if \"error\" in entry.groups | default([]) else\n                          {\"severity\": \"inhibitor\"} if \"inhibitor\" in entry.groups | default([]) else {}\n                        )\n                      ]\n                  }\n                )\n              }}\n          loop: \"{{ report_content.entries | default([]) }}\"\n          loop_control:\n            loop_var: entry\n\n        - name: Set message if inhibitors or errors present\n          set_fact:\n            message: >-\n              The upgrade cannot proceed. Your system has {{ error_count | int + inhibitor_count | int }} inhibitor{{ 's' if inhibitor_count | int + error_count | int != 1 else '' }}\n              out of {{ total_problems_count }} potential problems.\n          when: inhibitor_count != \"0\" or error_count != \"0\"\n\n\n        - name: Set message if no inhibitors and no errors present\n          set_fact:\n            message: >-\n              {{ 'No problems found. The system is ready for upgrade.' if  total_problems_count == 0\n              else 'The upgrade can proceed. However, there is one or more warnings about issues that might occur after the upgrade.'}}\n          when: inhibitor_count == \"0\" and error_count == \"0\"\n\n        - name: Set result\n          ansible.builtin.set_fact:\n            task_results:\n              report_json: \"{{ report_content_edited }}\"\n              report: \"{{ report_content_txt_raw.content | b64decode }}\"\n              message: \"{{ message }}\"\n              alert: \"{{ (inhibitor_count | int > 0) or (error_count | int > 0) }}\"\n\n    - name: Start insights-client for immediate data collection of leapp-report\n      ansible.builtin.shell: insights-client >/dev/null 2>&1 &\n      async: 10\n      poll: 0\n\n    - name: Print Task Result\n      ansible.builtin.debug:\n        var: task_results\n"
    }
  },
  {
    "model": "tasks.Task",
    "pk": 4,
    "fields": {
      "slug": "convert-to-rhel-analysis",
      "title": "Pre-conversion analysis for converting to RHEL",
      "description": "You can run the pre-conversion analysis task on CentOS Linux 7 systems that are connected to Insights. This task identifies potential issues and provides you with guidance on how to remediate these issues before you convert.\nAdditional documentation to complete the conversion experience can be found at [Converting from an RPM-based Linux distribution to RHEL](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/converting_from_an_rpm-based_linux_distribution_to_rhel/index).\nThis task supports the CentOS Linux 7 distribution. Refer to the [Convert2RHEL Support Policy](https://access.redhat.com/support/policy/convert2rhel-support) for specific version support.",
      "publish_date": "2022-10-05T00:00:00Z",
      "playbook": "# Auto-generated file, please do not edit manually.\n# Any updates should be made to upstream https://github.com/oamg/convert2rhel-insights-tasks.\n- name: Convert2RHEL Analysis\n  vars:\n    insights_signature: !!binary |\n      TFMwdExTMUNSVWRKVGlCUVIxQWdVMGxIVGtGVVZWSkZMUzB0TFMwS1ZtVnljMmx2YmpvZ1IyNTFV\n      RWNnZGpFS0NtbFJTV05DUVVGQ1EwRkJSMEpSU20wNVFuQlFRVUZ2U2tWTmRuYzFPRVFyYWpWd1Rr\n      eHBhMUF2TW5JeE1tSlJPV3RpTW5ObmRETm9Sa0owVjJsa1lUa0tlalozZGxKeFRYaHpiV2RJWVZS\n      bVVVWkllSFV4V0ZaMVRUSkVWWGQwTjBoaFJsUmhTVTk2V1hsSldIQjRkMU5aVGpoWlNVSnVlR052\n      WlZWTWFETjFid295VmtkcGNXZEpUVUUzYWk4M2JIbG1ZVzVZVWxkS1VFOW9VVTVIYUhScU5Wb3pN\n      bTB2VnpaNWVWQjNkbEk0UkZabmNHWmFTbUZwV1U0MFdIa3dVMXBWQ25OTk1uRnBRMkprVUVjeVEz\n      aGFiVFZFUjFKbWRqVTVZUzkzUlhrM1N6ZEVNMWxQTmtSRGNtVlRkRGt5VUhFd2NtbDJibFZEUVRG\n      c1lrRmxZbkpZZUZRS1oxWjRSQzgyZEhaeVNVdHhWbU5QYUd4TWFXMTZZMmQxY3pSeFVVcHNhR1J0\n      YTFWSE9EbENlbkZMUkVoTk16TlpjbUZNUW1vM1pHVXdSbmRKZVZKTE9BcEJWek5TWkVaWWRVNWhl\n      WGQ2V1U1VFozWlFVWE5VTXpsR0x6bFpMemxPU2xrd0wyaG9kMmRzUVRKNWEzTlNUbWxRUjNVd05s\n      cHJiRFZEWTAxcVdURndDazk2YVZkc2JtNU1NV2RFWldkQ1VWZDZNMHRFZFhGTVVtaFBkbWR3V21r\n      dlVWcEpRMGx4TkRKUlZYTkRaVTl1TUdSNmMxcFVlR3R4YzA1SFFXTk1lazhLTWpjeloyRkRVMGRo\n      YWxONWJFUmhkMEZRTm05M00wSmlZblpETjJ0MmFWUnNaSHBoTVVSeWRtOWtVa3d4UzNkUFMwZDJP\n      WFIyV0VWS2VHZDNOWFZ1TWdwNE9ESXhlWEpDU2xCR2FUSkJWWE5xYUU1RlJqaFRTa280Ulc1dVlU\n      YzFNVGRKUWpJeFdIaEtjbkUwUm5sNmJIUnJiRE4xTTNBdloxQkpVa293VW5WR0NtUXJUalF6UzNr\n      NWEwTnFZMHBPZUZKVWJrTlRUUzlEZGpaS1ZtTnRSMFExUlRJM1FsSmhaWEphZGpaS1QyRmtjRGN6\n      Vm1STWNYWTJkalJKUTBWUVUwUUtRVlV5Y1VsRk9XdGFlRmR0TWxsM01qRjNkMGd4ZVhVclVHSllU\n      MG81WWtKS1psaFlWMVJCYURaSlEweDBkU3RoY1hOMlVYSTJTMFYyUmk5UWVFWTFjQW8xVlVGWVNH\n      WTJXWGc0Y1Nzd09TOTNabTFSUmdvOVVVNXNPQW90TFMwdExVVk9SQ0JRUjFBZ1UwbEhUa0ZVVlZK\n      RkxTMHRMUzBL\n    insights_signature_exclude: /vars/insights_signature,/vars/content_vars\n    interpreter: /usr/bin/python2\n    content: |\n      import copy\n      import json\n      import logging\n      import os\n      import re\n      import shutil\n      import subprocess\n      import sys\n      from time import gmtime, strftime\n\n      from urllib2 import URLError, urlopen\n\n      # SCRIPT_TYPE is either 'CONVERSION' or 'ANALYSIS'\n      # Value is set in signed yaml envelope in content_vars (SCRIPT_MODE)\n      SCRIPT_TYPE = os.getenv(\"RHC_WORKER_SCRIPT_MODE\", \"\").upper()\n      IS_CONVERSION = SCRIPT_TYPE == \"CONVERSION\"\n      IS_ANALYSIS = SCRIPT_TYPE == \"ANALYSIS\"\n\n      STATUS_CODE = {\n          \"SUCCESS\": 0,\n          \"INFO\": 25,\n          \"WARNING\": 51,\n          \"SKIP\": 101,\n          \"OVERRIDABLE\": 152,\n          \"ERROR\": 202,\n      }\n\n      # Revert the `STATUS_CODE` dictionary to map number: name instead of name:\n      # number as used originally.\n      STATUS_CODE_NAME = {number: name for name, number in STATUS_CODE.items()}\n      # Log folder path for convert2rhel\n      C2R_LOG_FOLDER = \"/var/log/convert2rhel\"\n      # Log file for convert2rhel\n      C2R_LOG_FILE = \"%s/convert2rhel.log\" % C2R_LOG_FOLDER\n      # Path to the convert2rhel pre conversion report json file.\n      C2R_PRE_REPORT_FILE = \"%s/convert2rhel-pre-conversion.json\" % C2R_LOG_FOLDER\n      # Path to the convert2rhel post conversion report json file.\n      C2R_POST_REPORT_FILE = \"%s/convert2rhel-post-conversion.json\" % C2R_LOG_FOLDER\n      # Path to the convert2rhel pre report textual file.\n      C2R_PRE_REPORT_TXT_FILE = \"%s/convert2rhel-pre-conversion.txt\" % C2R_LOG_FOLDER\n      # Path to the convert2rhel post report textual file.\n      C2R_POST_REPORT_TXT_FILE = \"%s/convert2rhel-post-conversion.txt\" % C2R_LOG_FOLDER\n      # Path to the archive folder for convert2rhel.\n      C2R_ARCHIVE_DIR = \"%s/archive\" % C2R_LOG_FOLDER\n      # Set of yum transactions that will be rolled back after the operation is done.\n      YUM_TRANSACTIONS_TO_UNDO = set()\n\n      # Detect the last transaction id in yum.\n      LATEST_YUM_TRANSACTION_PATTERN = re.compile(r\"^(\\s+)?(\\d+)\", re.MULTILINE)\n\n      # Path to store the script logs\n      LOG_DIR = \"/var/log/convert2rhel-insights-tasks\"\n      # Log filename for the script. It will be created based on the script type of\n      # execution.\n      LOG_FILENAME = \"convert2rhel-insights-tasks-%s.log\" % (\n          \"conversion\" if IS_CONVERSION else \"analysis\"\n      )\n\n      # Path to the sos extras folder\n      SOS_REPORT_FOLDER = \"/etc/sos.extras.d\"\n      # Name of the file based on the conversion type for sos report\n      SOS_REPORT_FILE = \"convert2rhel-insights-tasks-%s-logs\" % (\n          \"conversion\" if IS_CONVERSION else \"analysis\"\n      )\n\n      DEFAULT_RHSM_CONVERT2RHEL_REPOS = \"rhel-7-server-rpms\"\n      DEFAULT_RHSM_CONVERT2RHEL_ELS_REPOS = \"rhel-7-server-els-rpms\"\n\n      logger = logging.getLogger(__name__)\n\n\n      class RequiredFile(object):\n          \"\"\"Holds data about files needed to download convert2rhel\"\"\"\n\n          def __init__(self, path=\"\", host=\"\", keep=False):\n              self.path = path\n              self.host = host\n              self.keep = keep  # conversion specific\n              self.backup_suffix = \".backup\"\n\n              self.backup_created = False\n              self.created = False\n\n          def create_from_host_url_data(self):\n              return self._create(urlopen(self.host).read())\n\n          def create_from_data(self, data):\n              return self._create(data)\n\n          def _create(self, data):\n              try:\n                  directory = os.path.dirname(self.path)\n                  if not os.path.exists(directory):\n                      logger.info(\"Creating directory at '%s'\", directory)\n                      os.makedirs(directory, mode=0o755)\n\n                  logger.info(\"Writing file to destination: '%s'\", self.path)\n                  with open(self.path, mode=\"w\") as handler:\n                      handler.write(data)\n                      os.chmod(self.path, 0o644)\n\n                  self.created = True\n              except OSError as err:\n                  logger.warning(\"Failed to write file to '%s':\\n %s\", self.path, err)\n                  return False\n              return True\n\n          def delete(self):\n              \"\"\"Deletes the file. Returns True if deleted, otherwise False.\"\"\"\n              if not self.created:\n                  return False\n\n              try:\n                  logger.info(\"Removing the previously downloaded file '%s'\", self.path)\n                  os.remove(self.path)\n              except OSError as err:\n                  logger.warning(\"Failed to remove '%s':\\n %s\", self.path, err)\n                  return False\n              return True\n\n          def restore(self):\n              \"\"\"Restores file backup (rename). Returns True if restored, otherwise False.\"\"\"\n              if not self.backup_created:\n                  return False\n\n              file_path = self.path + self.backup_suffix\n              try:\n                  logger.info(\"Restoring backed up file %s.\", file_path)\n                  os.rename(file_path, self.path)\n                  logger.info(\"File restored (%s).\", self.path)\n              except OSError as err:\n                  logger.warning(\"Failed to restore %s:\\n %s\", file_path, err)\n                  return False\n              return True\n\n          def backup(self):\n              \"\"\"Creates backup file (rename). Returns True if backed up, otherwise False.\"\"\"\n              if not os.path.exists(self.path):\n                  logger.info(\"File %s does not exist, no need to back up.\", self.path)\n                  return False\n\n              try:\n                  logger.info(\n                      \"Trying to create backup of %s (%s) ...\",\n                      self.path,\n                      self.backup_suffix,\n                  )\n                  full_path = self.path + self.backup_suffix\n                  os.rename(self.path, full_path)\n                  logger.info(\"Back up created (%s).\", full_path)\n                  self.backup_created = True\n              except OSError as err:\n                  logger.warning(\"Failed to create back up of %s (%s)\", self.path, err)\n                  return False\n              return True\n\n\n      class ProcessError(Exception):\n          \"\"\"Custom exception to report errors during setup and run of conver2rhel\"\"\"\n\n          def __init__(self, message, report):\n              super(ProcessError, self).__init__(report)\n              self.message = message\n              self.report = report\n\n\n      class OutputCollector(object):\n          \"\"\"Wrapper class for script expected stdout\"\"\"\n\n          # pylint: disable=too-many-instance-attributes\n          # pylint: disable=too-many-arguments\n          # Eight and five is reasonable in this case.\n\n          def __init__(\n              self, status=\"\", message=\"\", report=\"\", entries=None, alert=False, error=False\n          ):\n              self.status = status\n              self.alert = alert  # true if error true or if conversion inhibited\n              self.error = error  # true if the script wasn't able to finish, otherwise false\n              self.message = message\n              self.report = report\n              self.tasks_format_version = \"1.0\"\n              self.tasks_format_id = \"oamg-format\"\n              self.entries = entries\n              self.report_json = None\n\n          def to_dict(self):\n              # If we have entries, then we change report_json to be a dictionary\n              # with the needed values, otherwise, we leave it as `None` to be\n              # transformed to `null` in json.\n              if self.entries:\n                  self.report_json = {\n                      \"tasks_format_version\": self.tasks_format_version,\n                      \"tasks_format_id\": self.tasks_format_id,\n                      \"entries\": self.entries,\n                  }\n\n              return {\n                  \"status\": self.status,\n                  \"alert\": self.alert,\n                  \"error\": self.error,\n                  \"message\": self.message,\n                  \"report\": self.report,\n                  \"report_json\": self.report_json,\n              }\n\n\n      def setup_sos_report():\n          \"\"\"Setup sos report log collection.\"\"\"\n          if not os.path.exists(SOS_REPORT_FOLDER):\n              os.makedirs(SOS_REPORT_FOLDER)\n\n          script_log_file = os.path.join(LOG_DIR, LOG_FILENAME)\n          sosreport_link_file = os.path.join(SOS_REPORT_FOLDER, SOS_REPORT_FILE)\n          # In case the file for sos report does not exist, lets create one and add\n          # the log file path to it.\n          if not os.path.exists(sosreport_link_file):\n              with open(sosreport_link_file, mode=\"w\") as handler:\n                  handler.write(\":%s\\n\" % script_log_file)\n\n\n      def setup_logger_handler():\n          \"\"\"\n          Setup custom logging levels, handlers, and so on. Call this method from\n          your application's main start point.\n          \"\"\"\n          # Receive the log level from the worker and try to parse it. If the log\n          # level is not compatible with what the logging library expects, set the\n          # log level to INFO automatically.\n          log_level = os.getenv(\"RHC_WORKER_LOG_LEVEL\", \"INFO\").upper()\n          log_level = logging.getLevelName(log_level)\n          if isinstance(log_level, str):\n              log_level = logging.INFO\n\n          # enable raising exceptions\n          logger.propagate = True\n          logger.setLevel(log_level)\n\n          # create sys.stdout handler for info/debug\n          stdout_handler = logging.StreamHandler(sys.stdout)\n          formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n          stdout_handler.setFormatter(formatter)\n\n          # Create the directory if it don't exist\n          if not os.path.exists(LOG_DIR):\n              os.makedirs(LOG_DIR)\n\n          log_filepath = os.path.join(LOG_DIR, LOG_FILENAME)\n          file_handler = logging.FileHandler(log_filepath)\n          file_handler.setFormatter(formatter)\n\n          # can flush logs to the file that were logged before initializing the file handler\n          logger.addHandler(stdout_handler)\n          logger.addHandler(file_handler)\n\n\n      def archive_old_logger_files():\n          \"\"\"\n          Archive the old log files to not mess with multiple runs outputs. Every\n          time a new run begins, this method will be called to archive the previous\n          logs if there is a `convert2rhel.log` file there, it will be archived using\n          the same name for the log file, but having an appended timestamp to it.\n\n          For example:\n              /var/log/convert2rhel-insights-tasks/archive/convert2rhel-insights-tasks-1635162445070567607.log\n              /var/log/convert2rhel-insights-tasks/archive/convert2rhel-insights-tasks-1635162478219820043.log\n\n          This way, the user can track the logs for each run individually based on\n          the timestamp.\n          \"\"\"\n\n          current_log_file = os.path.join(LOG_DIR, LOG_FILENAME)\n          archive_log_dir = os.path.join(LOG_DIR, \"archive\")\n\n          # No log file found, that means it's a first run or it was manually deleted\n          if not os.path.exists(current_log_file):\n              return\n\n          stat = os.stat(current_log_file)\n\n          # Get the last modified time in UTC\n          last_modified_at = gmtime(stat.st_mtime)\n\n          # Format time to a human-readable format\n          formatted_time = strftime(\"%Y%m%dT%H%M%SZ\", last_modified_at)\n\n          # Create the directory if it don't exist\n          if not os.path.exists(archive_log_dir):\n              os.makedirs(archive_log_dir)\n\n          file_name, suffix = tuple(LOG_FILENAME.rsplit(\".\", 1))\n          archive_log_file = \"%s/%s-%s.%s\" % (\n              archive_log_dir,\n              file_name,\n              formatted_time,\n              suffix,\n          )\n          shutil.move(current_log_file, archive_log_file)\n\n\n      def get_rollback_failures(returncode):\n          \"\"\"Returns lines with errors in rollback section of c2r log file, or empty string.\"\"\"\n          rollback_failures = \"\"\n\n          if returncode != 1 or returncode is None:\n              return rollback_failures\n\n          logger.info(\n              \"Checking content of '%s' for possible rollback problems ...\", C2R_LOG_FILE\n          )\n\n          start_of_rollback_failures_section = (\n              \"Following errors were captured during rollback:\"\n          )\n          end_of_rollback_failures_section = \"DEBUG - /var/run/lock/convert2rhel.pid\"\n          try:\n              with open(C2R_LOG_FILE, mode=\"r\") as handler:\n                  # Skip the empty lines and strip white chars from start and end of the string.\n                  lines = [line.strip() for line in handler.readlines() if line.strip()]\n\n                  # Find index of first string in the logs that we care about.\n                  start_index = lines.index(start_of_rollback_failures_section)\n\n                  # Get the end index of the rollback failures section.\n                  # Find indexes of the \"DEBUG - /var/run/lock/convert2rhel.pid\" occurrences.\n                  end_message_occurrences = [\n                      i for i, s in enumerate(lines) if end_of_rollback_failures_section in s\n                  ]\n                  end_index = None\n                  # Find the first occurence of the end message after the beggining of rollback failures section.\n                  for occurence_index in end_message_occurrences:\n                      if occurence_index > start_index:\n                          end_index = occurence_index\n                          break\n                  # If the end message wasn't found, use the rest of the log.\n                  if not end_index:\n                      end_index = None\n\n                  rollback_failures = lines[start_index + 1 : end_index]\n          except ValueError:\n              logger.info(\n                  \"Failed to find rollback section ('%s') in '%s' file.\",\n                  start_of_rollback_failures_section,\n                  C2R_LOG_FILE,\n              )\n          except IOError:\n              logger.warning(\"Failed to read '%s' file.\", C2R_LOG_FILE)\n\n          return \"\\n\".join(rollback_failures)\n\n\n      def _check_ini_file_modified():\n          rpm_va_output, ini_file_not_modified = run_subprocess(\n              [\"/usr/bin/rpm\", \"-Va\", \"convert2rhel\"]\n          )\n\n          # No modifications at all\n          if not ini_file_not_modified:\n              return False\n\n          lines = rpm_va_output.strip().split(\"\\n\")\n          for line in lines:\n              line = line.strip().split()\n              status = line[0].replace(\".\", \"\").replace(\"?\", \"\")\n              path = line[-1]\n\n              default_ini_modified = path == \"/etc/convert2rhel.ini\"\n              md5_hash_mismatch = \"5\" in status\n\n              if default_ini_modified and md5_hash_mismatch:\n                  return True\n          return False\n\n\n      def check_convert2rhel_inhibitors_before_run():\n          \"\"\"\n          Conditions that must be True in order to run convert2rhel command.\n          \"\"\"\n          default_ini_path = \"/etc/convert2rhel.ini\"\n          custom_ini_path = os.path.expanduser(\"~/.convert2rhel.ini\")\n          logger.info(\n              \"Checking that '%s' wasn't modified and '%s' doesn't exist ...\",\n              default_ini_path,\n              custom_ini_path,\n          )\n\n          if os.path.exists(custom_ini_path):\n              raise ProcessError(\n                  message=\"Custom %s was found.\" % custom_ini_path,\n                  report=(\n                      \"Remove the %s file by running \"\n                      \"'rm -f %s' before running the Task again.\"\n                  )\n                  % (custom_ini_path, custom_ini_path),\n              )\n\n          if _check_ini_file_modified():\n              raise ProcessError(\n                  message=\"According to 'rpm -Va' command %s was modified.\"\n                  % default_ini_path,\n                  report=(\n                      \"Either remove the %s file by running \"\n                      \"'rm -f %s' or uninstall convert2rhel by running \"\n                      \"'yum remove convert2rhel' before running the Task again.\"\n                  )\n                  % (default_ini_path, default_ini_path),\n              )\n\n\n      def get_system_distro_version():\n          \"\"\"Currently we execute the task only for RHEL 7 or 8\"\"\"\n          logger.info(\"Checking OS distribution and version ID ...\")\n          try:\n              distribution_id = None\n              version_id = None\n              with open(\"/etc/system-release\", \"r\") as system_release_file:\n                  data = system_release_file.readline()\n              match = re.search(r\"(.+?)\\s?(?:release\\s?)\", data)\n              if match:\n                  # Split and get the first position, which will contain the system\n                  # name.\n                  distribution_id = match.group(1).lower()\n\n              match = re.search(r\".+?(\\d+)\\.(\\d+)\\D?\", data)\n              if match:\n                  version_id = \"%s.%s\" % (match.group(1), match.group(2))\n          except IOError:\n              logger.warning(\"Couldn't read /etc/system-release\")\n\n          logger.info(\n              \"Detected distribution='%s' in version='%s'\",\n              distribution_id,\n              version_id,\n          )\n          return distribution_id, version_id\n\n\n      def is_eligible_releases(release):\n          eligible_releases = \"7.9\"\n          return release == eligible_releases if release else False\n\n\n      def archive_report_file(file):\n          \"\"\"Archive json and textual report from convert2rhel on given filepath\"\"\"\n\n          if not os.path.exists(file):\n              logger.info(\"%s does not exist. Skipping archive.\", file)\n              return\n\n          stat = os.stat(file)\n          # Get the last modified time in UTC\n          last_modified_at = gmtime(stat.st_mtime)\n\n          # Format time to a human-readable format\n          formatted_time = strftime(\"%Y%m%dT%H%M%SZ\", last_modified_at)\n\n          # Create the directory if it don't exist\n          if not os.path.exists(C2R_ARCHIVE_DIR):\n              os.makedirs(C2R_ARCHIVE_DIR)\n\n          file_name, suffix = tuple(os.path.basename(file).rsplit(\".\", 1))\n          archive_log_file = \"%s/%s-%s.%s\" % (\n              C2R_ARCHIVE_DIR,\n              file_name,\n              formatted_time,\n              suffix,\n          )\n          shutil.move(file, archive_log_file)\n\n\n      def gather_json_report(report_file):\n          \"\"\"Collect the json report generated by convert2rhel.\"\"\"\n          logger.info(\"Collecting JSON report.\")\n\n          if not os.path.exists(report_file):\n              return {}\n\n          try:\n              with open(report_file, \"r\") as handler:\n                  data = json.load(handler)\n\n                  if not data:\n                      return {}\n          except ValueError:\n              # In case it is not a valid JSON content.\n              return {}\n\n          return data\n\n\n      def gather_textual_report(report_file):\n          \"\"\"\n          Collect the textual report generated by convert2rhel.\n\n              .. note::\n                  We are checking if file exists here as the textual report is not\n                  that important as the JSON report for the script and for Insights.\n                  It's fine if the textual report does not exist, but the JSON one is\n                  required.\n          \"\"\"\n          logger.info(\"Collecting TXT report.\")\n          data = \"\"\n          if os.path.exists(report_file):\n              with open(report_file, mode=\"r\") as handler:\n                  data = handler.read()\n          return data\n\n\n      def generate_report_message(highest_status):\n          \"\"\"Generate a report message based on the status severity.\"\"\"\n          message = \"\"\n          alert = False\n\n          conversion_succes_msg = (\n              \"No problems found. The system was converted successfully. Please,\"\n              \" reboot your system at your earliest convenience to make sure that\"\n              \" the system is using the RHEL kernel.\"\n          )\n\n          if STATUS_CODE[highest_status] < STATUS_CODE[\"WARNING\"]:\n              message = (\n                  conversion_succes_msg\n                  if IS_CONVERSION\n                  else \"No problems found. The system is ready for conversion.\"\n              )\n\n          if STATUS_CODE[highest_status] == STATUS_CODE[\"WARNING\"]:\n              message = (\n                  conversion_succes_msg\n                  if IS_CONVERSION\n                  else (\n                      \"The conversion can proceed. \"\n                      \"However, there is one or more warnings about issues that might occur after the conversion.\"\n                  )\n              )\n\n          if STATUS_CODE[highest_status] > STATUS_CODE[\"WARNING\"]:\n              message = \"The conversion cannot proceed. You must resolve existing issues to perform the conversion.\"\n              alert = True\n\n          return message, alert\n\n\n      def setup_convert2rhel(required_files):\n          \"\"\"Setup convert2rhel tool by downloading the required files.\"\"\"\n          logger.info(\"Downloading required files.\")\n          try:\n              for required_file in required_files:\n                  required_file.backup()\n                  required_file.create_from_host_url_data()\n          except URLError as err:\n              url = required_file.host\n              # pylint: disable=raise-missing-from\n              raise ProcessError(\n                  message=\"Failed to download required files needed for convert2rhel to run.\",\n                  report=\"Download of required file from %s failed with error: %s\"\n                  % (url, err),\n              )\n\n\n      # Code taken from\n      # https://github.com/oamg/convert2rhel/blob/v1.4.1/convert2rhel/utils.py#L345\n      # and modified to adapt the needs of the tools that are being executed in this\n      # script.\n      def run_subprocess(cmd, print_cmd=True, env=None):\n          \"\"\"\n          Call the passed command and optionally log the called command\n          (print_cmd=True) and environment variables in form of dictionary(env=None).\n          Switching off printing the command can be useful in case it contains a\n          password in plain text.\n\n          The cmd is specified as a list starting with the command and followed by a\n          list of arguments. Example: [\"/usr/bin/yum\", \"install\", \"<package>\"]\n          \"\"\"\n          # This check is here because we passed in strings in the past and changed\n          # to a list for security hardening.  Remove this once everyone is\n          # comfortable with using a list instead.\n          if isinstance(cmd, str):\n              raise TypeError(\"cmd should be a list, not a str\")\n\n          if print_cmd:\n              logger.info(\"Calling command '%s'\", \" \".join(cmd))\n\n          process = subprocess.Popen(\n              cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, bufsize=1, env=env\n          )\n          output = \"\"\n          for line in iter(process.stdout.readline, b\"\"):\n              line = line.decode(\"utf8\")\n              output += line\n\n          # Call wait() to wait for the process to terminate so that we can\n          # get the return code.\n          process.wait()\n\n          return output, process.returncode\n\n\n      def _get_last_yum_transaction_id(pkg_name):\n          output, return_code = run_subprocess([\"/usr/bin/yum\", \"history\", \"list\", pkg_name])\n          if return_code:\n              # NOTE: There is only print because list will exit with 1 when no such transaction exist\n              logger.warning(\n                  \"Listing yum transaction history for '%s' failed with exit status '%s' and output '%s'\"\n                  \"\\nThis may cause clean up function to not remove '%s' after Task run.\",\n                  pkg_name,\n                  return_code,\n                  output,\n                  pkg_name,\n              )\n              return None\n\n          matches = LATEST_YUM_TRANSACTION_PATTERN.findall(output)\n          return matches[-1][1] if matches else None\n\n\n      def _check_if_package_installed(pkg_name):\n          _, return_code = run_subprocess([\"/usr/bin/rpm\", \"-q\", pkg_name])\n          return return_code == 0\n\n\n      def install_or_update_convert2rhel(required_files):\n          \"\"\"\n          Install the convert2rhel tool to the system.\n          Returns True and transaction ID if the c2r pkg was installed, otherwise False, None.\n          \"\"\"\n          logger.info(\"Installing & updating Convert2RHEL package.\")\n\n          c2r_pkg_name = \"convert2rhel\"\n          c2r_installed = _check_if_package_installed(c2r_pkg_name)\n\n          if not c2r_installed:\n              setup_convert2rhel(required_files)\n              output, returncode = run_subprocess(\n                  [\"/usr/bin/yum\", \"install\", c2r_pkg_name, \"-y\"],\n              )\n              if returncode:\n                  raise ProcessError(\n                      message=\"Failed to install convert2rhel RPM.\",\n                      report=\"Installing convert2rhel with yum exited with code '%s' and output:\\n%s\"\n                      % (returncode, output.rstrip(\"\\n\")),\n                  )\n              transaction_id = _get_last_yum_transaction_id(c2r_pkg_name)\n              return True, transaction_id\n\n          output, returncode = run_subprocess([\"/usr/bin/yum\", \"update\", c2r_pkg_name, \"-y\"])\n          if returncode:\n              raise ProcessError(\n                  message=\"Failed to update convert2rhel RPM.\",\n                  report=\"Updating convert2rhel with yum exited with code '%s' and output:\\n%s\"\n                  % (returncode, output.rstrip(\"\\n\")),\n              )\n          # NOTE: If we would like to undo update we could use _get_last_yum_transaction_id(c2r_pkg_name)\n          return False, None\n\n\n      def prepare_environment_variables(env):\n          \"\"\"Prepare environment variables to be used in subprocess\n\n          This metod will prepare any environment variables before they are sent down\n          to the subprocess that will convert2rhel. Currently, this is meant to be a\n          workaround since convert2rhel does not parse the value of the environment\n          variables, but only check the presence of them in os.environ.\n\n          With this function, we are make sure that any variables that have the value\n          0 are ignored before setting them in the subprocess env context, this will\n          prevent convert2rhel to wrongly skipping checks because it was pre-defined\n          in the insights playbook.\n\n          :param env: The environment variables before setting them in subprocess.\n          :type env: dict[str, Any]\n          \"\"\"\n          for variable, value in env.items():\n              # We can pop out of context both the OPTIONAL_REPOSITORIES and\n              # ELS_DISABLED envs as they are not necessary for convert2rhel\n              # execution.\n              if variable in (\"OPTIONAL_REPOSITORIES\", \"ELS_DISABLED\"):\n                  env.pop(variable)\n\n              if variable.startswith(\"CONVERT2RHEL_\") and value == \"0\":\n                  env.pop(variable)\n          return env\n\n\n      def run_convert2rhel(env):\n          \"\"\"\n          Run the convert2rhel tool assigning the correct environment variables.\n\n          :param env: Dictionary of possible environment variables to passed down to\n              the process.\n          :type env: dict[str]\n          \"\"\"\n          logger.info(\"Running Convert2RHEL %s\", (SCRIPT_TYPE.title()))\n\n          command = [\"/usr/bin/convert2rhel\"]\n          if IS_ANALYSIS:\n              command.append(\"analyze\")\n\n          command.append(\"-y\")\n\n          repositories = []\n\n          # This will always be represented as either false/true, since this option\n          # comes from the input parameters through Insights UI.\n          els_disabled = json.loads(env.pop(\"ELS_DISABLED\", \"false\").lower())\n          if not bool(els_disabled):\n              command.append(\"--els\")\n              repositories.append(DEFAULT_RHSM_CONVERT2RHEL_ELS_REPOS)\n          else:\n              repositories.append(DEFAULT_RHSM_CONVERT2RHEL_REPOS)\n\n          # The `None` value that comes from the playbook gets converted to \"None\"\n          # when we parse it from the environment variable, to not mess with casting\n          # and converting, the easiest option is to check against that value for\n          # now.\n          # TODO(r0x0d): The ideal solution here would be coming with a pre-defined\n          # dictionary of values that have the correct values and types. Maybe for\n          # the future.\n          optional_repositories = env.pop(\"OPTIONAL_REPOSITORIES\", [])\n          if optional_repositories and optional_repositories != \"None\":\n              enablerepo_cmd = []\n              repositories.extend(optional_repositories.split(\",\"))\n              # Normalize the values removing whitespace. This is important for turning them into a set.\n              repositories = [repository.strip() for repository in repositories]\n              for repository in set(repositories):\n                  enablerepo_cmd.append(\"--enablerepo\")\n                  enablerepo_cmd.append(repository)\n\n              command.extend(enablerepo_cmd)\n\n          env = prepare_environment_variables(env)\n          output, returncode = run_subprocess(command, env=env)\n          return output, returncode\n\n\n      def parse_environment_variables():\n          \"\"\"Read the environment variable from os.environ and return them.\"\"\"\n          new_env = {}\n          for key, value in os.environ.items():\n              valid_prefix = \"RHC_WORKER_\"\n              if key.startswith(valid_prefix):\n                  # This also removes multiple valid prefixes\n                  new_env[key.replace(valid_prefix, \"\")] = value\n              else:\n                  new_env[key] = value\n          return new_env\n\n\n      def cleanup(required_files):\n          \"\"\"\n          Cleanup the downloaded files downloaded in previous steps in this script.\n\n          If any of the required files was already present on the system, the script\n          will not remove that file, as it understand that it is a system file and\n          not something that was downloaded by the script.\n          \"\"\"\n          logger.info(\"Cleaning up modifications to the system ...\")\n\n          for required_file in required_files:\n              if required_file.keep:\n                  continue\n              required_file.delete()\n              required_file.restore()\n\n          for transaction_id in YUM_TRANSACTIONS_TO_UNDO:\n              output, returncode = run_subprocess(\n                  [\"/usr/bin/yum\", \"history\", \"undo\", \"-y\", transaction_id],\n              )\n              if returncode:\n                  logger.warning(\n                      \"Undo of yum transaction with ID %s failed with exit status '%s' and output:\\n%s\",\n                      transaction_id,\n                      returncode,\n                      output,\n                  )\n\n\n      def _generate_message_key(message, action_id):\n          \"\"\"\n          Helper method to generate a key field in the message composed by action_id\n          and message_id.\n          Returns modified copy of original message.\n          \"\"\"\n          new_message = copy.deepcopy(message)\n\n          new_message[\"key\"] = \"%s::%s\" % (action_id, message[\"id\"])\n          del new_message[\"id\"]\n\n          return new_message\n\n\n      def _generate_detail_block(message):\n          \"\"\"\n          Helper method to generate the detail key that is composed by the\n          remediations and diagnosis fields.\n          Returns modified copy of original message.\n          \"\"\"\n          new_message = copy.deepcopy(message)\n          detail_block = {\n              \"remediations\": [],\n              \"diagnosis\": [],\n          }\n\n          remediation_key = \"remediations\" if \"remediations\" in new_message else \"remediation\"\n          detail_block[\"remediations\"].append(\n              {\"context\": new_message.pop(remediation_key, \"\")}\n          )\n          detail_block[\"diagnosis\"].append({\"context\": new_message.pop(\"diagnosis\", \"\")})\n          new_message[\"detail\"] = detail_block\n          return new_message\n\n\n      def _rename_dictionary_key(message, new_key, old_key):\n          \"\"\"Helper method to rename keys in a flatten dictionary.\"\"\"\n          new_message = copy.deepcopy(message)\n          new_message[new_key] = new_message.pop(old_key)\n          return new_message\n\n\n      def _filter_message_level(message, level):\n          \"\"\"\n          Filter for messages with specific level. If any of the message matches the\n          level, return None, otherwise, if it is different from what is expected,\n          return the message received to continue with the other transformations.\n          \"\"\"\n          if message[\"level\"] != level:\n              return message\n\n          return {}\n\n\n      def apply_message_transform(message, action_id):\n          \"\"\"Apply the necessary data transformation to the given messages.\"\"\"\n          if not _filter_message_level(message, level=\"SUCCESS\"):\n              return {}\n\n          new_message = _generate_message_key(message, action_id)\n          new_message = _rename_dictionary_key(new_message, \"severity\", \"level\")\n          new_message = _rename_dictionary_key(new_message, \"summary\", \"description\")\n          new_message = _generate_detail_block(new_message)\n\n          # Appending the `modifiers` key to the message here for now. Once we have\n          # this feature in the frontend, we can populate the data with it.\n          new_message[\"modifiers\"] = []\n\n          return new_message\n\n\n      def transform_raw_data(raw_data):\n          \"\"\"\n          Method that will transform the raw data given and output in the expected\n          format.\n\n          The expected format will be a flattened version of both results and\n          messages into a single\n          \"\"\"\n          new_data = []\n          for action_id, result in raw_data[\"actions\"].items():\n              # Format the results as a single list\n              for message in result[\"messages\"]:\n                  new_data.append(apply_message_transform(message, action_id))\n\n              new_data.append(apply_message_transform(result[\"result\"], action_id))\n\n          # Filter out None values before returning\n          return [data for data in new_data if data]\n\n\n      def update_insights_inventory():\n          \"\"\"\n          Call insights-client to update insights inventory.\n          \"\"\"\n          logger.info(\"Updating system status in Red Hat Insights.\")\n          output, returncode = run_subprocess(cmd=[\"/usr/bin/insights-client\"])\n\n          if returncode:\n              raise ProcessError(\n                  message=\"Conversion succeeded but update of Insights Inventory by registering the system again failed.\",\n                  report=\"insights-client execution exited with code '%s' and output:\\n%s\"\n                  % (returncode, output.rstrip(\"\\n\")),\n              )\n\n          logger.info(\"System registered with insights-client successfully.\")\n\n\n      def clean_yum_cache():\n          \"\"\"Clean the yum cache metadata to start with clean checks\"\"\"\n          output, ret_code = run_subprocess(\n              cmd=[\"/usr/bin/yum\", \"clean\", \"metadata\", \"--enablerepo=*\", \"--quiet\"]\n          )\n          logger.debug(\"Output of yum clean metadata:\\n%s\", output)\n\n          if ret_code != 0:\n              logger.warning(\"Failed to clean yum metadata:\\n%s\", output)\n              return\n\n          logger.info(\"Cached repositories metadata cleaned successfully.\")\n\n\n      def check_repos_are_valid():\n          \"\"\"Check if the repositories under /etc/yum.repos.d are available.\n\n          :raises ProcessExit: In case any of the repositories defined in that folder\n              is not available.\n          \"\"\"\n          logger.info(\"Checking for system repositories accessbility\")\n          output, return_code = run_subprocess(\n              cmd=[\"/usr/bin/yum\", \"makecache\", \"--setopt=*.skip_if_unavailable=False\"]\n          )\n\n          if return_code != 0:\n              # This will always print, and we know it is the last command before it\n              # tells us what is wrong.\n              match = \"yum-config-manager --save\"\n              output_lines = [line.strip() for line in output.split(\"\\n\") if line]\n\n              # Retrieve the index of the match by searching for that substring\n              # inside of the output_lines.\n              failure_index = [\n                  index for index, failure in enumerate(output_lines) if match in failure\n              ][0]\n\n              # For showing the errors, we actually want the index + 1, as the index\n              # itself will be the match, and we don't care about that part.\n              failures = output_lines[failure_index + 1 :]\n              raise ProcessError(\n                  message=\"Failed to verify accessibility of system repositories.\",\n                  report=\"The following repositories are not accessible: %s.\\n\\nFor more information, please visit https://access.redhat.com/solutions/7077708.\"\n                  % \"\\n\".join(failures),\n              )\n\n          logger.info(\"System repositories are acessible.\")\n\n\n      # pylint: disable=too-many-branches\n      # pylint: disable=too-many-statements\n      # pylint: disable=too-many-locals\n      def main():\n          \"\"\"Main entrypoint for the script.\"\"\"\n          output = OutputCollector()\n          gpg_key_file = RequiredFile(\n              path=\"/etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release\",\n              host=\"https://security.access.redhat.com/data/fd431d51.txt\",\n          )\n          c2r_repo = RequiredFile(\n              path=\"/etc/yum.repos.d/convert2rhel.repo\",\n              host=\"https://cdn-public.redhat.com/content/public/addon/dist/convert2rhel/server/7/7Server/x86_64/files/repofile.repo\",\n          )\n          required_files = [\n              gpg_key_file,\n              c2r_repo,\n          ]\n\n          convert2rhel_installed = False\n          # Flag that indicate if the (pre)conversion was successful or not.\n          execution_successful = False\n          # String to hold any errors that happened during rollback.\n          rollback_errors = \"\"\n\n          # Switched to True only after setup is called\n          do_cleanup = False\n\n          returncode = None\n\n          setup_sos_report()\n          archive_old_logger_files()\n          setup_logger_handler()\n\n          try:\n              # Exit if invalid value for SCRIPT_TYPE\n              if SCRIPT_TYPE not in [\"CONVERSION\", \"ANALYSIS\"]:\n                  raise ProcessError(\n                      message=\"Allowed values for RHC_WORKER_SCRIPT_MODE are 'CONVERSION' and 'ANALYSIS'.\",\n                      report='Exiting because RHC_WORKER_SCRIPT_MODE=\"%s\"' % SCRIPT_TYPE,\n                  )\n\n              # Exit if not CentOS 7.9\n              dist, version = get_system_distro_version()\n\n              # Just try (pre)conversion if we can't read the dist or version\n              # (e.g. /etc/system-release is missing), such state is logged in get_system_distro_version\n              check_dist_version(dist, version)\n\n              # First clean the yum cache metadata before trying to check for\n              # repositories availability.\n              clean_yum_cache()\n              check_repos_are_valid()\n\n              archive_report_file(C2R_PRE_REPORT_FILE)\n              archive_report_file(C2R_POST_REPORT_FILE)\n              archive_report_file(C2R_PRE_REPORT_TXT_FILE)\n              archive_report_file(C2R_POST_REPORT_TXT_FILE)\n\n              # Setup Convert2RHEL to be executed.\n              do_cleanup = True\n              convert2rhel_installed, transaction_id = install_or_update_convert2rhel(\n                  required_files\n              )\n              if convert2rhel_installed:\n                  YUM_TRANSACTIONS_TO_UNDO.add(transaction_id)\n\n              check_convert2rhel_inhibitors_before_run()\n              new_env = parse_environment_variables()\n              stdout, returncode = run_convert2rhel(new_env)\n              execution_successful = returncode == 0\n\n              # Returncode other than 0 can happen in three states in analysis mode:\n              #  1. In case there is another instance of convert2rhel running\n              #  2. In case of KeyboardInterrupt, SystemExit (misplaced by mistaked),\n              #     Exception not catched before.\n              #  3. There was an error during rollback. This result in return code 1.\n              # In any case, we should treat this as separate and give it higher\n              # priority. In case the returncode was non zero, we don't care about\n              # the rest and we should jump to the exception handling immediatly\n              if not execution_successful:\n                  rollback_errors = get_rollback_failures(returncode)\n                  # Check if there are any inhibitors in the rollback logging. This is\n                  # necessary in the case where the analysis was done successfully, but\n                  # there was an error in the rollback log.\n                  if rollback_errors:\n                      raise ProcessError(\n                          message=(\n                              \"A rollback of changes performed by convert2rhel failed. The system is in an undefined state. \"\n                              \"Recover the system from a backup or contact Red Hat support.\"\n                          ),\n                          report=(\n                              \"\\nFor details, refer to the convert2rhel log file on the host at \"\n                              \"/var/log/convert2rhel/convert2rhel.log. Relevant lines from log file: \\n%s\\n\"\n                          )\n                          % rollback_errors,\n                      )\n\n                  step = \"pre-conversion analysis\" if IS_ANALYSIS else \"conversion\"\n                  raise ProcessError(\n                      message=(\n                          \"An error occurred during the %s. For details, refer to \"\n                          \"the convert2rhel log file on the host at /var/log/convert2rhel/convert2rhel.log\"\n                      )\n                      % step,\n                      report=(\n                          \"convert2rhel exited with code %s.\\n\"\n                          \"Output of the failed command: %s\"\n                          % (returncode, stdout.rstrip(\"\\n\"))\n                      ),\n                  )\n\n              # Only call insights to update inventory on successful conversion.\n              if IS_CONVERSION:\n                  update_insights_inventory()\n\n              logger.info(\n                  \"Convert2RHEL %s script finished successfully!\", SCRIPT_TYPE.title()\n              )\n          except ProcessError as exception:\n              logger.error(exception.report)\n              output = OutputCollector(\n                  status=\"ERROR\",\n                  alert=True,\n                  error=False,\n                  message=exception.message,\n                  report=exception.report,\n              )\n          except Exception as exception:\n              logger.critical(str(exception))\n              output = OutputCollector(\n                  status=\"ERROR\",\n                  alert=True,\n                  error=False,\n                  message=\"An unexpected error occurred. Expand the row for more details.\",\n                  report=str(exception),\n              )\n          finally:\n              # Report file could be either the pre-conversion or post-conversion\n              # depending on the SCRIPT_TYPE and conversion status. For example:\n              #   - If the SCRIPT_TYPE is analysis, then we will always use pre-conversion report\n              #   - If the SCRIPT_TYPE is conversion, we gonna check the following:\n              #       - If the conversion was successful, use the post-conversion report\n              #       - Otherwise, we probably have the pre-conversion report, so let's use that.\n              json_report_file = C2R_PRE_REPORT_FILE\n              txt_report_file = C2R_PRE_REPORT_TXT_FILE\n              if IS_CONVERSION and not os.path.exists(C2R_PRE_REPORT_FILE):\n                  json_report_file = C2R_POST_REPORT_FILE\n                  txt_report_file = C2R_POST_REPORT_TXT_FILE\n\n              # Gather JSON report\n              data = gather_json_report(json_report_file)\n\n              if data:\n                  output.status = data.get(\"status\", None)\n\n                  if not rollback_errors:\n                      # At this point we know JSON report exists and no rollback errors occured\n                      # we can rewrite previous conversion message with more specific one (or add missing message)\n                      # and set alert\n                      output.message, output.alert = generate_report_message(output.status)\n\n                  is_successful_conversion = IS_CONVERSION and execution_successful\n\n                  if is_successful_conversion:\n                      gpg_key_file.keep = True\n\n                      # NOTE: When c2r statistics on insights are not reliant on rpm being installed\n                      # remove below line (=decide only based on install_or_update_convert2rhel() result)\n                      if convert2rhel_installed:\n                          YUM_TRANSACTIONS_TO_UNDO.remove(transaction_id)\n\n                      # NOTE: Keep always because added/updated pkg is also kept\n                      # (if repo existed, the .backup file will remain on system)\n                      c2r_repo.keep = True\n\n                  should_attach_entries_and_report = (\n                      IS_CONVERSION or IS_ANALYSIS\n                  ) or not is_successful_conversion\n                  if not output.report and should_attach_entries_and_report:\n                      # Try to attach the textual report in the report if we have json\n                      # report, otherwise, we would overwrite the report raised by the\n                      # exception.\n                      output.report = gather_textual_report(txt_report_file)\n\n                  if not rollback_errors and should_attach_entries_and_report:\n                      output.entries = transform_raw_data(data)\n\n              if do_cleanup:\n                  cleanup(required_files)\n\n              print(\"### JSON START ###\")\n              print(json.dumps(output.to_dict(), indent=4))\n              print(\"### JSON END ###\")\n\n\n      def check_dist_version(dist, version):\n          \"\"\"Check for dist and version. If they don't match, raise an ProcessError and stop the script.\"\"\"\n          if dist and version:\n              is_valid_dist = dist.startswith(\"centos\")\n              is_valid_version = is_eligible_releases(version)\n              if not is_valid_dist or not is_valid_version:\n                  raise ProcessError(\n                      message=\"Conversion is only supported on CentOS 7.9 distributions.\",\n                      report='Exiting because distribution=\"%s\" and version=\"%s\"'\n                      % (dist.title(), version),\n                  )\n\n\n      if __name__ == \"__main__\":\n          main()\n    content_vars:\n      CONVERT2RHEL_THROUGH_INSIGHTS: 1\n      SCRIPT_MODE: ANALYSIS\n      CONVERT2RHEL_ALLOW_UNAVAILABLE_KMODS: 0\n      CONVERT2RHEL_SKIP_KERNEL_CURRENCY_CHECK: 0\n      CONVERT2RHEL_OUTDATED_PACKAGE_CHECK_SKIP: 0\n      ELS_DISABLED: false\n# Multiple optional repository parameter values will be comma separated, for example:\n# rhel-7-server-optional-rpms,rhel-7-server-extras-rpms,rhel-7-server-supplementary-rpms\n      OPTIONAL_REPOSITORIES: None\n# Disable color for logging\n      NO_COLOR: 1\n",
      "active": true,
      "type": "S",
      "filters": [
        "centos",
        "os_v7"
      ],
      "filter_message": "Eligible systems for this task include CentOS systems that are registered via RHC"
    }
  },
  {
    "model": "tasks.Task",
    "pk": 5,
    "fields": {
      "slug": "leapp-upgrade",
      "title": "In-place upgrade from RHEL 8 to RHEL 9",
      "description": "You can upgrade connected RHEL 8 systems to RHEL 9. Run the \\\"Pre-upgrade analysis for in-place upgrade from RHEL 8\\\" task beforehand to identify and address potential issues that could block or cause problems after the upgrade.\n\nSystem will be upgraded to the new major version and rebooted. The new version can be then seen in the Inventory. Always back up your systems before running the task. \n\nThis task supports RHEL 8. Refer to the [Upgrading from RHEL 8 to RHEL 9](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/upgrading_from_rhel_8_to_rhel_9/index#planning-an-upgrade_upgrading-from-rhel-8-to-rhel-9)  for specific version support.",
      "active": false,
      "type": "A",
      "filters": [
        "rhel",
        "os_v8"
      ],
      "filter_message": "Eligible systems include RHEL 8 systems connected to console.redhat.com with rhc, or Satellite with Cloud Connector",
      "publish_date": "2022-10-05T00:00:00Z",
      "playbook": "- name: task for upgrading host machine using leapp upgrade\n  hosts: localhost\n  become: true\n  vars:\n    rhui_packages:\n      rhel7:\n        - src_pkg: rh-amazon-rhui-client\n          leapp_pkg: leapp-rhui-aws\n        - src_pkg: rh-amazon-rhui-client-sap-bundle\n          leapp_pkg: leapp-rhui-aws-sap-e4s\n        - src_pkg: rhui-azure-rhel7\n          leapp_pkg: leapp-rhui-azure\n        - src_pkg: rhui-azure-rhel7-base-sap-apps\n          leapp_pkg: leapp-rhui-azure-sap\n        - src_pkg: rhui-azure-rhel7-base-sap-ha\n          leapp_pkg: leapp-rhui-azure-sap\n        - src_pkg: google-rhui-client-rhel7\n          leapp_pkg: leapp-rhui-google\n        - src_pkg: google-rhui-client-rhel79-sap\n          leapp_pkg: leapp-rhui-google-sap\n      rhel8:\n        - src_pkg: rh-amazon-rhui-client\n          leapp_pkg: leapp-rhui-aws\n        - src_pkg: rh-amazon-rhui-client-sap-bundle-e4s\n          leapp_pkg: leapp-rhui-aws-sap-e4s\n        - src_pkg: rhui-azure-rhel8\n          leapp_pkg: leapp-rhui-azure\n        - src_pkg: rhui-azure-rhel8-eus\n          leapp_pkg: leapp-rhui-azure-eus\n        - src_pkg: rhui-azure-rhel8-sap-ha\n          leapp_pkg: leapp-rhui-azure-sap\n        - src_pkg: rhui-azure-rhel8-sapapps\n          leapp_pkg: leapp-rhui-azure-sap\n        - src_pkg: google-rhui-client-rhel8\n          leapp_pkg: leapp-rhui-google\n        - src_pkg: google-rhui-client-rhel8-sap\n          leapp_pkg: leapp-rhui-google-sap\n    upgrade_command: '/usr/bin/leapp upgrade --report-schema=1.2.0'\n    no_rhsm: false\n    is_leapp_upgrade_successful: false\n    insights_signature_exclude: /hosts,/vars/insights_signature\n    insights_signature: !!binary |\n      TFMwdExTMUNSVWRKVGlCUVIxQWdVMGxIVGtGVVZWSkZMUzB0TFMwS1ZtVnljMmx2YmpvZ1IyNTFV\n      RWNnZGpFS0NtbFJTV05DUVVGQ1EwRkJSMEpSU214NWEzWmlRVUZ2U2tWTmRuYzFPRVFyYWpWd1Ru\n      YzFNRkF2VW1sRVkzWkhiVXhIU1VscFUxVnVLek5YZFZCMVJGSUtNRkJtV1ROVmJpOVhTbmRLYm1W\n      blJEQTNkRnAwTVhOeGFsQmpla01yWm5CRE5YUTFTa0pXTWtGM1ZWaFFNVTQ0YlVVdllXSnJTRGh0\n      YTA5M1ptcDVWZ3B1UW5sR1VUQjNSa3hvZFRNMlowd3pWMjFGUTJNeE4wc3phSGM0UVhZNVZsTXJl\n      RkJFYjJwdWExSlVlSEozVkdSb2FEWldlR0pPZUhaeE1tdHFVVFpOQ25OT2IwWmFhSFVyYmt3NGRI\n      YzVNamx1S3k4M1FYSTJaeXRGYkdSU1p6bHpNVUZPWnpWR2QwcFlRMloyU1RGbEt6Tm9abTlNUldO\n      MlJXZ3dibXcyUlVZS2RqaGxiM2t4Y1hkb2JFbHBiRFZ1VUV4eFdWWTJhbXMzTm1kWmJYRlhSQzh3\n      YjFKMllsbDNNVFJVWWtwYU5tVnZaMkZoZEVGSU1XNHZOR2x2VlZVeFJnb3hTVmRDVUVSaWVuYzVO\n      RGRsWkVaYVUzZDJaMDVhTVZJeVlVWTVPRmw1V1ZVd1kyaGlZMlpaVVZNd05GZG5ha1ZHYTNSWFR6\n      RTFaMFUzUnk5TVoyNVRDbmhVTDJkQ2NERm9ja3BCYkV0UlIzTlJOV1JHUjFBMloxSm9NMWxyU0Vo\n      dldEUjZXbFZpTWtaS04wbzJNM1JvYldOVGNrNWlTaTlITVZaT2NVOXdabWNLY2tNNE1EZzVZMlpr\n      ZW1sU2NtdzFSVkJUZDJOWVpXaERVVEJFWkRjeGJHMWtkRGhDUjFsQmJtcEVPWEoxTlVSTVdUZHBT\n      Mk5ZTDFaR2VqRmhUbnBqTHdwbVYyZ3JNMkU1UVhONGRUTlFWbTR3ZEdOMVpXWTRMMVpyYTBSSk1F\n      WnZURnA2TTFBM1lVUlRSaTlyZGtscFdGVnFkMGtyZURRNFNYQTNWSGN6Vm14NkNsTTRaVGwyTURB\n      M2RrSnZhVUZDVWtJd1EyUXpkVXN5T1VWeU1ESkhXa1ZWVG1KelpYTk1hWGhKWlhoVGVIWTNSa2hP\n      Vm1WVFl6VjBSRnBwWkROcVNGUUtVVUZWVldKVFMzZENVREI1VkdwVmJ6aExVRkJVWTFSblVXdDBT\n      SGxzU2paSWNUZ3lLMkU1YjNSalUyaGFPQzlqVm1WRE1WSmxUMnBSTVZscmRWVkxVQXA2U0VOblRH\n      NU5lVTlvVlRGM01VVjJTblZWVmdvOU5FeDNhUW90TFMwdExVVk9SQ0JRUjFBZ1UwbEhUa0ZVVlZK\n      RkxTMHRMUzBL\n  tasks:\n    - name: Exit for non-eligible releases\n      ansible.builtin.meta: end_host\n      when:\n        - ansible_distribution != 'Red Hat Enterprise Linux'\n        - ansible_distribution_major_version <= '6'\n        - ansible_distribution_major_version >= '9'\n\n    - name: Gather package facts\n      package_facts:\n        manager: auto\n\n    - name: Set rhui_packages_found to empty list\n      set_fact:\n        rhui_packages_found: []\n\n    - name: Do RHEL7 specific tasks\n      block:\n        - name: Install Leapp from RHEL 7 Extras\n          yum:\n            name: leapp-upgrade\n            state: latest\n            enablerepo: rhel-7-server-extras-rpms\n        - name: Determine if any RHUI packages are installed on RHEL 7\n          set_fact:\n            rhui_packages_found: \"{{ rhui_packages_found + [item] }}\"\n          loop: \"{{ rhui_packages.rhel7 }}\"\n          when: item.src_pkg in ansible_facts.packages.keys()\n      when: ansible_distribution_major_version == '7'\n\n    - name: Do RHEL8 specific tasks\n      block:\n        - name: Install Leapp on RHEL 8\n          dnf:\n            name: leapp-upgrade\n            state: latest\n        - name: Determine if any RHUI packages are installed on RHEL 8\n          set_fact:\n            rhui_packages_found: \"{{ rhui_packages_found + [item] }}\"\n          loop: \"{{ rhui_packages.rhel8 }}\"\n          when: item.src_pkg in ansible_facts.packages.keys()\n      when: ansible_distribution_major_version == '8'\n\n    - name: Determine --no-rhsm flag usage and do corresponding steps when rhsm cannot be used\n      block:\n        - name: Check if subscription-manager is installed\n          command: which subscription-manager\n          changed_when: false\n          failed_when: false\n          register: rhsm_installed_check\n\n        - name: Check if system has repositories available\n          ansible.builtin.command: \"subscription-manager repos --list-enabled\"\n          register: rhsm_repo_check\n          changed_when: false\n          failed_when: false\n          when: rhsm_installed_check is success\n\n        - name: Set rhsm_repo_check_fail if there are no available repositories through RHSM\n          set_fact:\n            rhsm_repo_check_fail: true\n          when:\n            - >\n              'This system has no repositories available through subscriptions.' in rhsm_repo_check.stdout_lines or\n              'Repositories disabled by configuration.' in rhsm_repo_check.stdout_lines\n\n        - name: Set no_rhsm flag to true if RHUI package are found AND (there are no available repositories OR subscription-manager is not installed)\n          set_fact:\n            no_rhsm: true\n          when:\n            - rhui_packages_found | length > 0\n            - rhsm_installed_check is failed or rhsm_repo_check_fail is defined\n\n        - name: Add --no-rhsm switch to leapp upgrade command if no_rhsm flag is true\n          set_fact:\n            upgrade_command: \"{{ upgrade_command }} --no-rhsm\"\n          when: no_rhsm == true\n\n        - name: Install corresponding leapp_pkg for installed RHUI packages if no_rhsm flag is true\n          yum:\n            name: \"{{ item.leapp_pkg }}\"\n            state: latest\n          loop: \"{{ rhui_packages_found }}\"\n          when: no_rhsm == true\n\n    - name: Execute leapp upgrade\n      ansible.builtin.shell: \"{{ upgrade_command }} || true\"\n      register: leapp_upgrade_result\n      no_log: true\n      ignore_errors: true\n\n    - name: debug last 5 lines of leapp upgrade output\n      ansible.builtin.debug:\n        msg: \"{{ leapp_upgrade_result.stdout_lines[-5:] }}\"\n\n    - name: Set leapp upgrade result as true if reboot guidance message is found\n      set_fact:\n        is_leapp_upgrade_successful: true\n      when: '\"A reboot is required to continue. Please reboot your system.\" in leapp_upgrade_result.stdout'\n\n    - name: Prepare report content\n      block:\n        - name: Read json report\n          ansible.builtin.slurp:\n            src: '/var/log/leapp/leapp-report.json'\n          register: report_content_raw\n\n        - name: Read text report\n          ansible.builtin.slurp:\n            src: '/var/log/leapp/leapp-report.txt'\n          register: report_content_txt_raw\n\n        - name: Set report fact\n          ansible.builtin.set_fact:\n            report_content: \"{{ report_content_raw.content | b64decode }}\"\n\n        - name: Set total problems count\n          ansible.builtin.set_fact:\n            total_problems_count: \"{{ report_content.entries | length }}\"\n\n        - name: Set inhibitor count\n          ansible.builtin.set_fact:\n            inhibitor_count: \"{{ report_content.entries | selectattr('groups', 'defined') | selectattr('groups', 'contains', 'inhibitor') | list | length }}\"\n\n        - name: Set errors count\n          ansible.builtin.set_fact:\n            error_count: \"{{ report_content.entries | selectattr('groups', 'defined') | selectattr('groups', 'contains', 'error') | list | length }}\"\n\n        - name: Init new empty entries for report with edited severity\n          ansible.builtin.set_fact:\n            report_content_edited: >-\n              {{\n                {\n                  \"entries\": []\n                }\n              }}\n\n        - name: Transform severities in leapp report to distinguish errors and inhibitors from other high risks entries\n          set_fact:\n            report_content_edited: >-\n              {{\n                report_content_edited | combine(\n                  {\n                    \"entries\": report_content_edited.entries | default([]) +\n                      [\n                        entry | combine(\n                          {\"severity\": \"inhibitor\"} if \"error\" in entry.groups | default([]) else\n                          {\"severity\": \"inhibitor\"} if \"inhibitor\" in entry.groups | default([]) else {}\n                        )\n                      ]\n                  }\n                )\n              }}\n          loop: \"{{ report_content.entries | default([]) }}\"\n          loop_control:\n            loop_var: entry\n\n    - name: Prepare final result\n      block:\n        - name: Set default fail message\n          set_fact:\n            message: >-\n              The upgrade cannot proceed.\n              Your system has {{ error_count | int + inhibitor_count | int }} inhibitor{{ 's' if inhibitor_count | int + error_count | int != 1 else '' }}\n              out of {{ total_problems_count }} potential problems.\n\n        - name: Set message if leapp upgrade succeeded\n          set_fact:\n            message: >-\n              No problems found. The system will be upgraded. Rebooting system in 1 minute.\n              After reboot check inventory to verify the RHEL system is registered with new major version.\n          when: is_leapp_upgrade_successful is true\n\n        - name: Set report content as empty if upgrade was successful\n          set_fact:\n            report_content_edited: \"\"\n          when: is_leapp_upgrade_successful is true\n\n        - name: Set result\n          ansible.builtin.set_fact:\n            task_results:\n              report_json: \"{{ report_content_edited }}\"\n              report: \"{{ report_content_txt_raw.content | b64decode }}\"\n              message: \"{{ message }}\"\n              alert: \"{{ not is_leapp_upgrade_successful }}\"\n\n    - name: Start insights-client for immediate data collection of leapp-report\n      ansible.builtin.shell: insights-client >/dev/null 2>&1\n\n    - name: Schedule reboot and Insights report if leapp upgrade is successful\n      block:\n        - name: Schedule insights-client after boot\n          file:\n            path: \"/etc/insights-client/.run_insights_client_next_boot\"\n            state: touch\n        - name: Enable boot service\n          systemd:\n            name: insights-client-boot.service\n            enabled: true\n          ignore_errors: true\n        - name: Schedule system reboot for 1 minute in the future\n          shell: shutdown -r +1 \"Ansible triggered reboot\"\n          ignore_errors: true\n      when: is_leapp_upgrade_successful is true\n\n    - name: Print Task Result\n      ansible.builtin.debug:\n        var: task_results\n"
    }
  },
  {
    "model": "tasks.Task",
    "pk": 6,
    "fields": {
      "slug": "convert-to-rhel-conversion",
      "title": "Convert to RHEL from CentOS Linux 7",
      "description": "Convert CentOS Linux 7 systems that are connected to Insights to RHEL. Run the “Pre-conversion analysis for converting to RHEL” task beforehand to identify and address potential issues that could block or cause problems after the conversion.\n\nThis task supports the CentOS Linux 7 distribution. Refer to the [Convert2RHEL Support Policy](https://access.redhat.com/support/policy/convert2rhel-support) for specific version support.",
      "publish_date": "2023-11-08T00:00:00Z",
      "playbook": "# Auto-generated file, please do not edit manually.\n# Any updates should be made to upstream https://github.com/oamg/convert2rhel-insights-tasks.\n- name: Convert2RHEL Conversion\n  vars:\n    insights_signature: !!binary |\n      TFMwdExTMUNSVWRKVGlCUVIxQWdVMGxIVGtGVVZWSkZMUzB0TFMwS1ZtVnljMmx2YmpvZ1IyNTFV\n      RWNnZGpFS0NtbFJTV05DUVVGQ1EwRkJSMEpSU20wNVFuQllRVUZ2U2tWTmRuYzFPRVFyYWpWd1Rq\n      QlFjMUF2TWpaeVQxVjFiREJwYTFKa1pHNXVlSFJRYkhwTVJEWUtUamRUWlVGU1RIRnBNVTV5Y1dZ\n      cmJIa3dTRWxtTDJveU5FdzBWVkUzYVZCWFRVWmFWRk51T0VreGQyeFBORnAwUkZkR2QycGpRVEp4\n      TkRscUwzWmpWd3BFZDNORE9UVjJaRzgzZW5wQmRrZEJiVEZoVGxwV2F6Tk1UV28zZUROaVYzUkxj\n      bFZSZG1weWNqbDRXaTlxYTNOYVlsUm9hakZRWVVoTE1XZFFkemRWQ21aeFltVXlSSFZvVmtoelZY\n      STFZa1ZyV1VWUmFtMTNRMGQ2VWxGcFoyVnNkVU14WjNkRlNHSkRkVVZ1ZW1SallVa3ZkMmRoTm5o\n      aVVqRkNlbU4yVW0wS1duQk5lRU5YVTBWd1RIQlBSbWxyVWxGemEwbFlka1l3TDNWTlNrUTFhR0Za\n      YTFkU2FIRkZWVVJCYW05Vk9XOVZZV2MzV25Wa2RGRm5kM1ZxVkhSTU13bzJaV3RKTm1Nd016QTNl\n      bmRMU1RGU1oyTTBXVUo2U1VWdlNWZ3lTRVo2WVdweWVXWlFNSFZhTUhaeVFXSlVkVWwwVWxOaGNG\n      QnVVRk5PUlRWclExZFBDbWsyVEZnMFFpdGpRVU5qYXpjMWEySkhORTVwUWxCeE5GQjNlVWN6T0RG\n      UlpYZHRaMnh6WW5RM2IzUlZWRVYyUlZVM01EQTBlQzk1ZUZSTVMwcEtSakFLWTB3eVJsRldjV0ZU\n      VFZGR2N6VkxhMUZLVmpsUVZuZzVTVE1yV1VsUVdDc3Zla1JZWlhCRFNtSnJRMWhIYUUxUVdWaEpR\n      MmhJTTJsd2NteG9aRWw2Y0FwYVZrUTRNRlIwVFZwTFp5OVNaazlsUTJ4c1VYTmFiSFJaV1dWeVRV\n      a3dRVVppV1hsbVNWaEthR2g2Vm5wa1kwbHRiWGxNVUVFeWRsVnRTMHhJSzBSckNuVXhXRzVWUkha\n      SlJrUlFPVmR1VEU0M1ltSnBVbU41WkVnM1RqaFFhR3B5WTBkTFZsVkJUVGQ1WTJkNmVGbElXa1ZI\n      U1hsV2VUTlJWRmcyT0RaNFNrNEtWVVJaUjJad1dDOXpWMlE0U2tsUVNXNXVVWFkyVTNCTFNDdEdX\n      RlZsYVc1aVpVWlZWMmRSTWpoc2FYa3pTV3R4TkM5RlNsSnNNRlIxWlhOSk55OTVRd293VVVaYVp6\n      RnpSbVJuYXk5dFlYVmxjemQ0TWdvOVRUaHdaUW90TFMwdExVVk9SQ0JRUjFBZ1UwbEhUa0ZVVlZK\n      RkxTMHRMUzBL\n    insights_signature_exclude: /vars/insights_signature,/vars/content_vars\n    interpreter: /usr/bin/python2\n    content: |\n      import copy\n      import json\n      import logging\n      import os\n      import re\n      import shutil\n      import subprocess\n      import sys\n      from time import gmtime, strftime\n\n      from urllib2 import URLError, urlopen\n\n      # SCRIPT_TYPE is either 'CONVERSION' or 'ANALYSIS'\n      # Value is set in signed yaml envelope in content_vars (SCRIPT_MODE)\n      SCRIPT_TYPE = os.getenv(\"RHC_WORKER_SCRIPT_MODE\", \"\").upper()\n      IS_CONVERSION = SCRIPT_TYPE == \"CONVERSION\"\n      IS_ANALYSIS = SCRIPT_TYPE == \"ANALYSIS\"\n\n      STATUS_CODE = {\n          \"SUCCESS\": 0,\n          \"INFO\": 25,\n          \"WARNING\": 51,\n          \"SKIP\": 101,\n          \"OVERRIDABLE\": 152,\n          \"ERROR\": 202,\n      }\n\n      # Revert the `STATUS_CODE` dictionary to map number: name instead of name:\n      # number as used originally.\n      STATUS_CODE_NAME = {number: name for name, number in STATUS_CODE.items()}\n      # Log folder path for convert2rhel\n      C2R_LOG_FOLDER = \"/var/log/convert2rhel\"\n      # Log file for convert2rhel\n      C2R_LOG_FILE = \"%s/convert2rhel.log\" % C2R_LOG_FOLDER\n      # Path to the convert2rhel pre conversion report json file.\n      C2R_PRE_REPORT_FILE = \"%s/convert2rhel-pre-conversion.json\" % C2R_LOG_FOLDER\n      # Path to the convert2rhel post conversion report json file.\n      C2R_POST_REPORT_FILE = \"%s/convert2rhel-post-conversion.json\" % C2R_LOG_FOLDER\n      # Path to the convert2rhel pre report textual file.\n      C2R_PRE_REPORT_TXT_FILE = \"%s/convert2rhel-pre-conversion.txt\" % C2R_LOG_FOLDER\n      # Path to the convert2rhel post report textual file.\n      C2R_POST_REPORT_TXT_FILE = \"%s/convert2rhel-post-conversion.txt\" % C2R_LOG_FOLDER\n      # Path to the archive folder for convert2rhel.\n      C2R_ARCHIVE_DIR = \"%s/archive\" % C2R_LOG_FOLDER\n      # Set of yum transactions that will be rolled back after the operation is done.\n      YUM_TRANSACTIONS_TO_UNDO = set()\n\n      # Detect the last transaction id in yum.\n      LATEST_YUM_TRANSACTION_PATTERN = re.compile(r\"^(\\s+)?(\\d+)\", re.MULTILINE)\n\n      # Path to store the script logs\n      LOG_DIR = \"/var/log/convert2rhel-insights-tasks\"\n      # Log filename for the script. It will be created based on the script type of\n      # execution.\n      LOG_FILENAME = \"convert2rhel-insights-tasks-%s.log\" % (\n          \"conversion\" if IS_CONVERSION else \"analysis\"\n      )\n\n      # Path to the sos extras folder\n      SOS_REPORT_FOLDER = \"/etc/sos.extras.d\"\n      # Name of the file based on the conversion type for sos report\n      SOS_REPORT_FILE = \"convert2rhel-insights-tasks-%s-logs\" % (\n          \"conversion\" if IS_CONVERSION else \"analysis\"\n      )\n\n      DEFAULT_RHSM_CONVERT2RHEL_REPOS = \"rhel-7-server-rpms\"\n      DEFAULT_RHSM_CONVERT2RHEL_ELS_REPOS = \"rhel-7-server-els-rpms\"\n\n      logger = logging.getLogger(__name__)\n\n\n      class RequiredFile(object):\n          \"\"\"Holds data about files needed to download convert2rhel\"\"\"\n\n          def __init__(self, path=\"\", host=\"\", keep=False):\n              self.path = path\n              self.host = host\n              self.keep = keep  # conversion specific\n              self.backup_suffix = \".backup\"\n\n              self.backup_created = False\n              self.created = False\n\n          def create_from_host_url_data(self):\n              return self._create(urlopen(self.host).read())\n\n          def create_from_data(self, data):\n              return self._create(data)\n\n          def _create(self, data):\n              try:\n                  directory = os.path.dirname(self.path)\n                  if not os.path.exists(directory):\n                      logger.info(\"Creating directory at '%s'\", directory)\n                      os.makedirs(directory, mode=0o755)\n\n                  logger.info(\"Writing file to destination: '%s'\", self.path)\n                  with open(self.path, mode=\"w\") as handler:\n                      handler.write(data)\n                      os.chmod(self.path, 0o644)\n\n                  self.created = True\n              except OSError as err:\n                  logger.warning(\"Failed to write file to '%s':\\n %s\", self.path, err)\n                  return False\n              return True\n\n          def delete(self):\n              \"\"\"Deletes the file. Returns True if deleted, otherwise False.\"\"\"\n              if not self.created:\n                  return False\n\n              try:\n                  logger.info(\"Removing the previously downloaded file '%s'\", self.path)\n                  os.remove(self.path)\n              except OSError as err:\n                  logger.warning(\"Failed to remove '%s':\\n %s\", self.path, err)\n                  return False\n              return True\n\n          def restore(self):\n              \"\"\"Restores file backup (rename). Returns True if restored, otherwise False.\"\"\"\n              if not self.backup_created:\n                  return False\n\n              file_path = self.path + self.backup_suffix\n              try:\n                  logger.info(\"Restoring backed up file %s.\", file_path)\n                  os.rename(file_path, self.path)\n                  logger.info(\"File restored (%s).\", self.path)\n              except OSError as err:\n                  logger.warning(\"Failed to restore %s:\\n %s\", file_path, err)\n                  return False\n              return True\n\n          def backup(self):\n              \"\"\"Creates backup file (rename). Returns True if backed up, otherwise False.\"\"\"\n              if not os.path.exists(self.path):\n                  logger.info(\"File %s does not exist, no need to back up.\", self.path)\n                  return False\n\n              try:\n                  logger.info(\n                      \"Trying to create backup of %s (%s) ...\",\n                      self.path,\n                      self.backup_suffix,\n                  )\n                  full_path = self.path + self.backup_suffix\n                  os.rename(self.path, full_path)\n                  logger.info(\"Back up created (%s).\", full_path)\n                  self.backup_created = True\n              except OSError as err:\n                  logger.warning(\"Failed to create back up of %s (%s)\", self.path, err)\n                  return False\n              return True\n\n\n      class ProcessError(Exception):\n          \"\"\"Custom exception to report errors during setup and run of conver2rhel\"\"\"\n\n          def __init__(self, message, report):\n              super(ProcessError, self).__init__(report)\n              self.message = message\n              self.report = report\n\n\n      class OutputCollector(object):\n          \"\"\"Wrapper class for script expected stdout\"\"\"\n\n          # pylint: disable=too-many-instance-attributes\n          # pylint: disable=too-many-arguments\n          # Eight and five is reasonable in this case.\n\n          def __init__(\n              self, status=\"\", message=\"\", report=\"\", entries=None, alert=False, error=False\n          ):\n              self.status = status\n              self.alert = alert  # true if error true or if conversion inhibited\n              self.error = error  # true if the script wasn't able to finish, otherwise false\n              self.message = message\n              self.report = report\n              self.tasks_format_version = \"1.0\"\n              self.tasks_format_id = \"oamg-format\"\n              self.entries = entries\n              self.report_json = None\n\n          def to_dict(self):\n              # If we have entries, then we change report_json to be a dictionary\n              # with the needed values, otherwise, we leave it as `None` to be\n              # transformed to `null` in json.\n              if self.entries:\n                  self.report_json = {\n                      \"tasks_format_version\": self.tasks_format_version,\n                      \"tasks_format_id\": self.tasks_format_id,\n                      \"entries\": self.entries,\n                  }\n\n              return {\n                  \"status\": self.status,\n                  \"alert\": self.alert,\n                  \"error\": self.error,\n                  \"message\": self.message,\n                  \"report\": self.report,\n                  \"report_json\": self.report_json,\n              }\n\n\n      def setup_sos_report():\n          \"\"\"Setup sos report log collection.\"\"\"\n          if not os.path.exists(SOS_REPORT_FOLDER):\n              os.makedirs(SOS_REPORT_FOLDER)\n\n          script_log_file = os.path.join(LOG_DIR, LOG_FILENAME)\n          sosreport_link_file = os.path.join(SOS_REPORT_FOLDER, SOS_REPORT_FILE)\n          # In case the file for sos report does not exist, lets create one and add\n          # the log file path to it.\n          if not os.path.exists(sosreport_link_file):\n              with open(sosreport_link_file, mode=\"w\") as handler:\n                  handler.write(\":%s\\n\" % script_log_file)\n\n\n      def setup_logger_handler():\n          \"\"\"\n          Setup custom logging levels, handlers, and so on. Call this method from\n          your application's main start point.\n          \"\"\"\n          # Receive the log level from the worker and try to parse it. If the log\n          # level is not compatible with what the logging library expects, set the\n          # log level to INFO automatically.\n          log_level = os.getenv(\"RHC_WORKER_LOG_LEVEL\", \"INFO\").upper()\n          log_level = logging.getLevelName(log_level)\n          if isinstance(log_level, str):\n              log_level = logging.INFO\n\n          # enable raising exceptions\n          logger.propagate = True\n          logger.setLevel(log_level)\n\n          # create sys.stdout handler for info/debug\n          stdout_handler = logging.StreamHandler(sys.stdout)\n          formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n          stdout_handler.setFormatter(formatter)\n\n          # Create the directory if it don't exist\n          if not os.path.exists(LOG_DIR):\n              os.makedirs(LOG_DIR)\n\n          log_filepath = os.path.join(LOG_DIR, LOG_FILENAME)\n          file_handler = logging.FileHandler(log_filepath)\n          file_handler.setFormatter(formatter)\n\n          # can flush logs to the file that were logged before initializing the file handler\n          logger.addHandler(stdout_handler)\n          logger.addHandler(file_handler)\n\n\n      def archive_old_logger_files():\n          \"\"\"\n          Archive the old log files to not mess with multiple runs outputs. Every\n          time a new run begins, this method will be called to archive the previous\n          logs if there is a `convert2rhel.log` file there, it will be archived using\n          the same name for the log file, but having an appended timestamp to it.\n\n          For example:\n              /var/log/convert2rhel-insights-tasks/archive/convert2rhel-insights-tasks-1635162445070567607.log\n              /var/log/convert2rhel-insights-tasks/archive/convert2rhel-insights-tasks-1635162478219820043.log\n\n          This way, the user can track the logs for each run individually based on\n          the timestamp.\n          \"\"\"\n\n          current_log_file = os.path.join(LOG_DIR, LOG_FILENAME)\n          archive_log_dir = os.path.join(LOG_DIR, \"archive\")\n\n          # No log file found, that means it's a first run or it was manually deleted\n          if not os.path.exists(current_log_file):\n              return\n\n          stat = os.stat(current_log_file)\n\n          # Get the last modified time in UTC\n          last_modified_at = gmtime(stat.st_mtime)\n\n          # Format time to a human-readable format\n          formatted_time = strftime(\"%Y%m%dT%H%M%SZ\", last_modified_at)\n\n          # Create the directory if it don't exist\n          if not os.path.exists(archive_log_dir):\n              os.makedirs(archive_log_dir)\n\n          file_name, suffix = tuple(LOG_FILENAME.rsplit(\".\", 1))\n          archive_log_file = \"%s/%s-%s.%s\" % (\n              archive_log_dir,\n              file_name,\n              formatted_time,\n              suffix,\n          )\n          shutil.move(current_log_file, archive_log_file)\n\n\n      def get_rollback_failures(returncode):\n          \"\"\"Returns lines with errors in rollback section of c2r log file, or empty string.\"\"\"\n          rollback_failures = \"\"\n\n          if returncode != 1 or returncode is None:\n              return rollback_failures\n\n          logger.info(\n              \"Checking content of '%s' for possible rollback problems ...\", C2R_LOG_FILE\n          )\n\n          start_of_rollback_failures_section = (\n              \"Following errors were captured during rollback:\"\n          )\n          end_of_rollback_failures_section = \"DEBUG - /var/run/lock/convert2rhel.pid\"\n          try:\n              with open(C2R_LOG_FILE, mode=\"r\") as handler:\n                  # Skip the empty lines and strip white chars from start and end of the string.\n                  lines = [line.strip() for line in handler.readlines() if line.strip()]\n\n                  # Find index of first string in the logs that we care about.\n                  start_index = lines.index(start_of_rollback_failures_section)\n\n                  # Get the end index of the rollback failures section.\n                  # Find indexes of the \"DEBUG - /var/run/lock/convert2rhel.pid\" occurrences.\n                  end_message_occurrences = [\n                      i for i, s in enumerate(lines) if end_of_rollback_failures_section in s\n                  ]\n                  end_index = None\n                  # Find the first occurence of the end message after the beggining of rollback failures section.\n                  for occurence_index in end_message_occurrences:\n                      if occurence_index > start_index:\n                          end_index = occurence_index\n                          break\n                  # If the end message wasn't found, use the rest of the log.\n                  if not end_index:\n                      end_index = None\n\n                  rollback_failures = lines[start_index + 1 : end_index]\n          except ValueError:\n              logger.info(\n                  \"Failed to find rollback section ('%s') in '%s' file.\",\n                  start_of_rollback_failures_section,\n                  C2R_LOG_FILE,\n              )\n          except IOError:\n              logger.warning(\"Failed to read '%s' file.\", C2R_LOG_FILE)\n\n          return \"\\n\".join(rollback_failures)\n\n\n      def _check_ini_file_modified():\n          rpm_va_output, ini_file_not_modified = run_subprocess(\n              [\"/usr/bin/rpm\", \"-Va\", \"convert2rhel\"]\n          )\n\n          # No modifications at all\n          if not ini_file_not_modified:\n              return False\n\n          lines = rpm_va_output.strip().split(\"\\n\")\n          for line in lines:\n              line = line.strip().split()\n              status = line[0].replace(\".\", \"\").replace(\"?\", \"\")\n              path = line[-1]\n\n              default_ini_modified = path == \"/etc/convert2rhel.ini\"\n              md5_hash_mismatch = \"5\" in status\n\n              if default_ini_modified and md5_hash_mismatch:\n                  return True\n          return False\n\n\n      def check_convert2rhel_inhibitors_before_run():\n          \"\"\"\n          Conditions that must be True in order to run convert2rhel command.\n          \"\"\"\n          default_ini_path = \"/etc/convert2rhel.ini\"\n          custom_ini_path = os.path.expanduser(\"~/.convert2rhel.ini\")\n          logger.info(\n              \"Checking that '%s' wasn't modified and '%s' doesn't exist ...\",\n              default_ini_path,\n              custom_ini_path,\n          )\n\n          if os.path.exists(custom_ini_path):\n              raise ProcessError(\n                  message=\"Custom %s was found.\" % custom_ini_path,\n                  report=(\n                      \"Remove the %s file by running \"\n                      \"'rm -f %s' before running the Task again.\"\n                  )\n                  % (custom_ini_path, custom_ini_path),\n              )\n\n          if _check_ini_file_modified():\n              raise ProcessError(\n                  message=\"According to 'rpm -Va' command %s was modified.\"\n                  % default_ini_path,\n                  report=(\n                      \"Either remove the %s file by running \"\n                      \"'rm -f %s' or uninstall convert2rhel by running \"\n                      \"'yum remove convert2rhel' before running the Task again.\"\n                  )\n                  % (default_ini_path, default_ini_path),\n              )\n\n\n      def get_system_distro_version():\n          \"\"\"Currently we execute the task only for RHEL 7 or 8\"\"\"\n          logger.info(\"Checking OS distribution and version ID ...\")\n          try:\n              distribution_id = None\n              version_id = None\n              with open(\"/etc/system-release\", \"r\") as system_release_file:\n                  data = system_release_file.readline()\n              match = re.search(r\"(.+?)\\s?(?:release\\s?)\", data)\n              if match:\n                  # Split and get the first position, which will contain the system\n                  # name.\n                  distribution_id = match.group(1).lower()\n\n              match = re.search(r\".+?(\\d+)\\.(\\d+)\\D?\", data)\n              if match:\n                  version_id = \"%s.%s\" % (match.group(1), match.group(2))\n          except IOError:\n              logger.warning(\"Couldn't read /etc/system-release\")\n\n          logger.info(\n              \"Detected distribution='%s' in version='%s'\",\n              distribution_id,\n              version_id,\n          )\n          return distribution_id, version_id\n\n\n      def is_eligible_releases(release):\n          eligible_releases = \"7.9\"\n          return release == eligible_releases if release else False\n\n\n      def archive_report_file(file):\n          \"\"\"Archive json and textual report from convert2rhel on given filepath\"\"\"\n\n          if not os.path.exists(file):\n              logger.info(\"%s does not exist. Skipping archive.\", file)\n              return\n\n          stat = os.stat(file)\n          # Get the last modified time in UTC\n          last_modified_at = gmtime(stat.st_mtime)\n\n          # Format time to a human-readable format\n          formatted_time = strftime(\"%Y%m%dT%H%M%SZ\", last_modified_at)\n\n          # Create the directory if it don't exist\n          if not os.path.exists(C2R_ARCHIVE_DIR):\n              os.makedirs(C2R_ARCHIVE_DIR)\n\n          file_name, suffix = tuple(os.path.basename(file).rsplit(\".\", 1))\n          archive_log_file = \"%s/%s-%s.%s\" % (\n              C2R_ARCHIVE_DIR,\n              file_name,\n              formatted_time,\n              suffix,\n          )\n          shutil.move(file, archive_log_file)\n\n\n      def gather_json_report(report_file):\n          \"\"\"Collect the json report generated by convert2rhel.\"\"\"\n          logger.info(\"Collecting JSON report.\")\n\n          if not os.path.exists(report_file):\n              return {}\n\n          try:\n              with open(report_file, \"r\") as handler:\n                  data = json.load(handler)\n\n                  if not data:\n                      return {}\n          except ValueError:\n              # In case it is not a valid JSON content.\n              return {}\n\n          return data\n\n\n      def gather_textual_report(report_file):\n          \"\"\"\n          Collect the textual report generated by convert2rhel.\n\n              .. note::\n                  We are checking if file exists here as the textual report is not\n                  that important as the JSON report for the script and for Insights.\n                  It's fine if the textual report does not exist, but the JSON one is\n                  required.\n          \"\"\"\n          logger.info(\"Collecting TXT report.\")\n          data = \"\"\n          if os.path.exists(report_file):\n              with open(report_file, mode=\"r\") as handler:\n                  data = handler.read()\n          return data\n\n\n      def generate_report_message(highest_status):\n          \"\"\"Generate a report message based on the status severity.\"\"\"\n          message = \"\"\n          alert = False\n\n          conversion_succes_msg = (\n              \"No problems found. The system was converted successfully. Please,\"\n              \" reboot your system at your earliest convenience to make sure that\"\n              \" the system is using the RHEL kernel.\"\n          )\n\n          if STATUS_CODE[highest_status] < STATUS_CODE[\"WARNING\"]:\n              message = (\n                  conversion_succes_msg\n                  if IS_CONVERSION\n                  else \"No problems found. The system is ready for conversion.\"\n              )\n\n          if STATUS_CODE[highest_status] == STATUS_CODE[\"WARNING\"]:\n              message = (\n                  conversion_succes_msg\n                  if IS_CONVERSION\n                  else (\n                      \"The conversion can proceed. \"\n                      \"However, there is one or more warnings about issues that might occur after the conversion.\"\n                  )\n              )\n\n          if STATUS_CODE[highest_status] > STATUS_CODE[\"WARNING\"]:\n              message = \"The conversion cannot proceed. You must resolve existing issues to perform the conversion.\"\n              alert = True\n\n          return message, alert\n\n\n      def setup_convert2rhel(required_files):\n          \"\"\"Setup convert2rhel tool by downloading the required files.\"\"\"\n          logger.info(\"Downloading required files.\")\n          try:\n              for required_file in required_files:\n                  required_file.backup()\n                  required_file.create_from_host_url_data()\n          except URLError as err:\n              url = required_file.host\n              # pylint: disable=raise-missing-from\n              raise ProcessError(\n                  message=\"Failed to download required files needed for convert2rhel to run.\",\n                  report=\"Download of required file from %s failed with error: %s\"\n                  % (url, err),\n              )\n\n\n      # Code taken from\n      # https://github.com/oamg/convert2rhel/blob/v1.4.1/convert2rhel/utils.py#L345\n      # and modified to adapt the needs of the tools that are being executed in this\n      # script.\n      def run_subprocess(cmd, print_cmd=True, env=None):\n          \"\"\"\n          Call the passed command and optionally log the called command\n          (print_cmd=True) and environment variables in form of dictionary(env=None).\n          Switching off printing the command can be useful in case it contains a\n          password in plain text.\n\n          The cmd is specified as a list starting with the command and followed by a\n          list of arguments. Example: [\"/usr/bin/yum\", \"install\", \"<package>\"]\n          \"\"\"\n          # This check is here because we passed in strings in the past and changed\n          # to a list for security hardening.  Remove this once everyone is\n          # comfortable with using a list instead.\n          if isinstance(cmd, str):\n              raise TypeError(\"cmd should be a list, not a str\")\n\n          if print_cmd:\n              logger.info(\"Calling command '%s'\", \" \".join(cmd))\n\n          process = subprocess.Popen(\n              cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, bufsize=1, env=env\n          )\n          output = \"\"\n          for line in iter(process.stdout.readline, b\"\"):\n              line = line.decode(\"utf8\")\n              output += line\n\n          # Call wait() to wait for the process to terminate so that we can\n          # get the return code.\n          process.wait()\n\n          return output, process.returncode\n\n\n      def _get_last_yum_transaction_id(pkg_name):\n          output, return_code = run_subprocess([\"/usr/bin/yum\", \"history\", \"list\", pkg_name])\n          if return_code:\n              # NOTE: There is only print because list will exit with 1 when no such transaction exist\n              logger.warning(\n                  \"Listing yum transaction history for '%s' failed with exit status '%s' and output '%s'\"\n                  \"\\nThis may cause clean up function to not remove '%s' after Task run.\",\n                  pkg_name,\n                  return_code,\n                  output,\n                  pkg_name,\n              )\n              return None\n\n          matches = LATEST_YUM_TRANSACTION_PATTERN.findall(output)\n          return matches[-1][1] if matches else None\n\n\n      def _check_if_package_installed(pkg_name):\n          _, return_code = run_subprocess([\"/usr/bin/rpm\", \"-q\", pkg_name])\n          return return_code == 0\n\n\n      def install_or_update_convert2rhel(required_files):\n          \"\"\"\n          Install the convert2rhel tool to the system.\n          Returns True and transaction ID if the c2r pkg was installed, otherwise False, None.\n          \"\"\"\n          logger.info(\"Installing & updating Convert2RHEL package.\")\n\n          c2r_pkg_name = \"convert2rhel\"\n          c2r_installed = _check_if_package_installed(c2r_pkg_name)\n\n          if not c2r_installed:\n              setup_convert2rhel(required_files)\n              output, returncode = run_subprocess(\n                  [\"/usr/bin/yum\", \"install\", c2r_pkg_name, \"-y\"],\n              )\n              if returncode:\n                  raise ProcessError(\n                      message=\"Failed to install convert2rhel RPM.\",\n                      report=\"Installing convert2rhel with yum exited with code '%s' and output:\\n%s\"\n                      % (returncode, output.rstrip(\"\\n\")),\n                  )\n              transaction_id = _get_last_yum_transaction_id(c2r_pkg_name)\n              return True, transaction_id\n\n          output, returncode = run_subprocess([\"/usr/bin/yum\", \"update\", c2r_pkg_name, \"-y\"])\n          if returncode:\n              raise ProcessError(\n                  message=\"Failed to update convert2rhel RPM.\",\n                  report=\"Updating convert2rhel with yum exited with code '%s' and output:\\n%s\"\n                  % (returncode, output.rstrip(\"\\n\")),\n              )\n          # NOTE: If we would like to undo update we could use _get_last_yum_transaction_id(c2r_pkg_name)\n          return False, None\n\n\n      def prepare_environment_variables(env):\n          \"\"\"Prepare environment variables to be used in subprocess\n\n          This metod will prepare any environment variables before they are sent down\n          to the subprocess that will convert2rhel. Currently, this is meant to be a\n          workaround since convert2rhel does not parse the value of the environment\n          variables, but only check the presence of them in os.environ.\n\n          With this function, we are make sure that any variables that have the value\n          0 are ignored before setting them in the subprocess env context, this will\n          prevent convert2rhel to wrongly skipping checks because it was pre-defined\n          in the insights playbook.\n\n          :param env: The environment variables before setting them in subprocess.\n          :type env: dict[str, Any]\n          \"\"\"\n          for variable, value in env.items():\n              # We can pop out of context both the OPTIONAL_REPOSITORIES and\n              # ELS_DISABLED envs as they are not necessary for convert2rhel\n              # execution.\n              if variable in (\"OPTIONAL_REPOSITORIES\", \"ELS_DISABLED\"):\n                  env.pop(variable)\n\n              if variable.startswith(\"CONVERT2RHEL_\") and value == \"0\":\n                  env.pop(variable)\n          return env\n\n\n      def run_convert2rhel(env):\n          \"\"\"\n          Run the convert2rhel tool assigning the correct environment variables.\n\n          :param env: Dictionary of possible environment variables to passed down to\n              the process.\n          :type env: dict[str]\n          \"\"\"\n          logger.info(\"Running Convert2RHEL %s\", (SCRIPT_TYPE.title()))\n\n          command = [\"/usr/bin/convert2rhel\"]\n          if IS_ANALYSIS:\n              command.append(\"analyze\")\n\n          command.append(\"-y\")\n\n          repositories = []\n\n          # This will always be represented as either false/true, since this option\n          # comes from the input parameters through Insights UI.\n          els_disabled = json.loads(env.pop(\"ELS_DISABLED\", \"false\").lower())\n          if not bool(els_disabled):\n              command.append(\"--els\")\n              repositories.append(DEFAULT_RHSM_CONVERT2RHEL_ELS_REPOS)\n          else:\n              repositories.append(DEFAULT_RHSM_CONVERT2RHEL_REPOS)\n\n          # The `None` value that comes from the playbook gets converted to \"None\"\n          # when we parse it from the environment variable, to not mess with casting\n          # and converting, the easiest option is to check against that value for\n          # now.\n          # TODO(r0x0d): The ideal solution here would be coming with a pre-defined\n          # dictionary of values that have the correct values and types. Maybe for\n          # the future.\n          optional_repositories = env.pop(\"OPTIONAL_REPOSITORIES\", [])\n          if optional_repositories and optional_repositories != \"None\":\n              enablerepo_cmd = []\n              repositories.extend(optional_repositories.split(\",\"))\n              # Normalize the values removing whitespace. This is important for turning them into a set.\n              repositories = [repository.strip() for repository in repositories]\n              for repository in set(repositories):\n                  enablerepo_cmd.append(\"--enablerepo\")\n                  enablerepo_cmd.append(repository)\n\n              command.extend(enablerepo_cmd)\n\n          env = prepare_environment_variables(env)\n          output, returncode = run_subprocess(command, env=env)\n          return output, returncode\n\n\n      def parse_environment_variables():\n          \"\"\"Read the environment variable from os.environ and return them.\"\"\"\n          new_env = {}\n          for key, value in os.environ.items():\n              valid_prefix = \"RHC_WORKER_\"\n              if key.startswith(valid_prefix):\n                  # This also removes multiple valid prefixes\n                  new_env[key.replace(valid_prefix, \"\")] = value\n              else:\n                  new_env[key] = value\n          return new_env\n\n\n      def cleanup(required_files):\n          \"\"\"\n          Cleanup the downloaded files downloaded in previous steps in this script.\n\n          If any of the required files was already present on the system, the script\n          will not remove that file, as it understand that it is a system file and\n          not something that was downloaded by the script.\n          \"\"\"\n          logger.info(\"Cleaning up modifications to the system ...\")\n\n          for required_file in required_files:\n              if required_file.keep:\n                  continue\n              required_file.delete()\n              required_file.restore()\n\n          for transaction_id in YUM_TRANSACTIONS_TO_UNDO:\n              output, returncode = run_subprocess(\n                  [\"/usr/bin/yum\", \"history\", \"undo\", \"-y\", transaction_id],\n              )\n              if returncode:\n                  logger.warning(\n                      \"Undo of yum transaction with ID %s failed with exit status '%s' and output:\\n%s\",\n                      transaction_id,\n                      returncode,\n                      output,\n                  )\n\n\n      def _generate_message_key(message, action_id):\n          \"\"\"\n          Helper method to generate a key field in the message composed by action_id\n          and message_id.\n          Returns modified copy of original message.\n          \"\"\"\n          new_message = copy.deepcopy(message)\n\n          new_message[\"key\"] = \"%s::%s\" % (action_id, message[\"id\"])\n          del new_message[\"id\"]\n\n          return new_message\n\n\n      def _generate_detail_block(message):\n          \"\"\"\n          Helper method to generate the detail key that is composed by the\n          remediations and diagnosis fields.\n          Returns modified copy of original message.\n          \"\"\"\n          new_message = copy.deepcopy(message)\n          detail_block = {\n              \"remediations\": [],\n              \"diagnosis\": [],\n          }\n\n          remediation_key = \"remediations\" if \"remediations\" in new_message else \"remediation\"\n          detail_block[\"remediations\"].append(\n              {\"context\": new_message.pop(remediation_key, \"\")}\n          )\n          detail_block[\"diagnosis\"].append({\"context\": new_message.pop(\"diagnosis\", \"\")})\n          new_message[\"detail\"] = detail_block\n          return new_message\n\n\n      def _rename_dictionary_key(message, new_key, old_key):\n          \"\"\"Helper method to rename keys in a flatten dictionary.\"\"\"\n          new_message = copy.deepcopy(message)\n          new_message[new_key] = new_message.pop(old_key)\n          return new_message\n\n\n      def _filter_message_level(message, level):\n          \"\"\"\n          Filter for messages with specific level. If any of the message matches the\n          level, return None, otherwise, if it is different from what is expected,\n          return the message received to continue with the other transformations.\n          \"\"\"\n          if message[\"level\"] != level:\n              return message\n\n          return {}\n\n\n      def apply_message_transform(message, action_id):\n          \"\"\"Apply the necessary data transformation to the given messages.\"\"\"\n          if not _filter_message_level(message, level=\"SUCCESS\"):\n              return {}\n\n          new_message = _generate_message_key(message, action_id)\n          new_message = _rename_dictionary_key(new_message, \"severity\", \"level\")\n          new_message = _rename_dictionary_key(new_message, \"summary\", \"description\")\n          new_message = _generate_detail_block(new_message)\n\n          # Appending the `modifiers` key to the message here for now. Once we have\n          # this feature in the frontend, we can populate the data with it.\n          new_message[\"modifiers\"] = []\n\n          return new_message\n\n\n      def transform_raw_data(raw_data):\n          \"\"\"\n          Method that will transform the raw data given and output in the expected\n          format.\n\n          The expected format will be a flattened version of both results and\n          messages into a single\n          \"\"\"\n          new_data = []\n          for action_id, result in raw_data[\"actions\"].items():\n              # Format the results as a single list\n              for message in result[\"messages\"]:\n                  new_data.append(apply_message_transform(message, action_id))\n\n              new_data.append(apply_message_transform(result[\"result\"], action_id))\n\n          # Filter out None values before returning\n          return [data for data in new_data if data]\n\n\n      def update_insights_inventory():\n          \"\"\"\n          Call insights-client to update insights inventory.\n          \"\"\"\n          logger.info(\"Updating system status in Red Hat Insights.\")\n          output, returncode = run_subprocess(cmd=[\"/usr/bin/insights-client\"])\n\n          if returncode:\n              raise ProcessError(\n                  message=\"Conversion succeeded but update of Insights Inventory by registering the system again failed.\",\n                  report=\"insights-client execution exited with code '%s' and output:\\n%s\"\n                  % (returncode, output.rstrip(\"\\n\")),\n              )\n\n          logger.info(\"System registered with insights-client successfully.\")\n\n\n      def clean_yum_cache():\n          \"\"\"Clean the yum cache metadata to start with clean checks\"\"\"\n          output, ret_code = run_subprocess(\n              cmd=[\"/usr/bin/yum\", \"clean\", \"metadata\", \"--enablerepo=*\", \"--quiet\"]\n          )\n          logger.debug(\"Output of yum clean metadata:\\n%s\", output)\n\n          if ret_code != 0:\n              logger.warning(\"Failed to clean yum metadata:\\n%s\", output)\n              return\n\n          logger.info(\"Cached repositories metadata cleaned successfully.\")\n\n\n      def check_repos_are_valid():\n          \"\"\"Check if the repositories under /etc/yum.repos.d are available.\n\n          :raises ProcessExit: In case any of the repositories defined in that folder\n              is not available.\n          \"\"\"\n          logger.info(\"Checking for system repositories accessbility\")\n          output, return_code = run_subprocess(\n              cmd=[\"/usr/bin/yum\", \"makecache\", \"--setopt=*.skip_if_unavailable=False\"]\n          )\n\n          if return_code != 0:\n              # This will always print, and we know it is the last command before it\n              # tells us what is wrong.\n              match = \"yum-config-manager --save\"\n              output_lines = [line.strip() for line in output.split(\"\\n\") if line]\n\n              # Retrieve the index of the match by searching for that substring\n              # inside of the output_lines.\n              failure_index = [\n                  index for index, failure in enumerate(output_lines) if match in failure\n              ][0]\n\n              # For showing the errors, we actually want the index + 1, as the index\n              # itself will be the match, and we don't care about that part.\n              failures = output_lines[failure_index + 1 :]\n              raise ProcessError(\n                  message=\"Failed to verify accessibility of system repositories.\",\n                  report=\"The following repositories are not accessible: %s.\\n\\nFor more information, please visit https://access.redhat.com/solutions/7077708.\"\n                  % \"\\n\".join(failures),\n              )\n\n          logger.info(\"System repositories are acessible.\")\n\n\n      # pylint: disable=too-many-branches\n      # pylint: disable=too-many-statements\n      # pylint: disable=too-many-locals\n      def main():\n          \"\"\"Main entrypoint for the script.\"\"\"\n          output = OutputCollector()\n          gpg_key_file = RequiredFile(\n              path=\"/etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release\",\n              host=\"https://security.access.redhat.com/data/fd431d51.txt\",\n          )\n          c2r_repo = RequiredFile(\n              path=\"/etc/yum.repos.d/convert2rhel.repo\",\n              host=\"https://cdn-public.redhat.com/content/public/addon/dist/convert2rhel/server/7/7Server/x86_64/files/repofile.repo\",\n          )\n          required_files = [\n              gpg_key_file,\n              c2r_repo,\n          ]\n\n          convert2rhel_installed = False\n          # Flag that indicate if the (pre)conversion was successful or not.\n          execution_successful = False\n          # String to hold any errors that happened during rollback.\n          rollback_errors = \"\"\n\n          # Switched to True only after setup is called\n          do_cleanup = False\n\n          returncode = None\n\n          setup_sos_report()\n          archive_old_logger_files()\n          setup_logger_handler()\n\n          try:\n              # Exit if invalid value for SCRIPT_TYPE\n              if SCRIPT_TYPE not in [\"CONVERSION\", \"ANALYSIS\"]:\n                  raise ProcessError(\n                      message=\"Allowed values for RHC_WORKER_SCRIPT_MODE are 'CONVERSION' and 'ANALYSIS'.\",\n                      report='Exiting because RHC_WORKER_SCRIPT_MODE=\"%s\"' % SCRIPT_TYPE,\n                  )\n\n              # Exit if not CentOS 7.9\n              dist, version = get_system_distro_version()\n\n              # Just try (pre)conversion if we can't read the dist or version\n              # (e.g. /etc/system-release is missing), such state is logged in get_system_distro_version\n              check_dist_version(dist, version)\n\n              # First clean the yum cache metadata before trying to check for\n              # repositories availability.\n              clean_yum_cache()\n              check_repos_are_valid()\n\n              archive_report_file(C2R_PRE_REPORT_FILE)\n              archive_report_file(C2R_POST_REPORT_FILE)\n              archive_report_file(C2R_PRE_REPORT_TXT_FILE)\n              archive_report_file(C2R_POST_REPORT_TXT_FILE)\n\n              # Setup Convert2RHEL to be executed.\n              do_cleanup = True\n              convert2rhel_installed, transaction_id = install_or_update_convert2rhel(\n                  required_files\n              )\n              if convert2rhel_installed:\n                  YUM_TRANSACTIONS_TO_UNDO.add(transaction_id)\n\n              check_convert2rhel_inhibitors_before_run()\n              new_env = parse_environment_variables()\n              stdout, returncode = run_convert2rhel(new_env)\n              execution_successful = returncode == 0\n\n              # Returncode other than 0 can happen in three states in analysis mode:\n              #  1. In case there is another instance of convert2rhel running\n              #  2. In case of KeyboardInterrupt, SystemExit (misplaced by mistaked),\n              #     Exception not catched before.\n              #  3. There was an error during rollback. This result in return code 1.\n              # In any case, we should treat this as separate and give it higher\n              # priority. In case the returncode was non zero, we don't care about\n              # the rest and we should jump to the exception handling immediatly\n              if not execution_successful:\n                  rollback_errors = get_rollback_failures(returncode)\n                  # Check if there are any inhibitors in the rollback logging. This is\n                  # necessary in the case where the analysis was done successfully, but\n                  # there was an error in the rollback log.\n                  if rollback_errors:\n                      raise ProcessError(\n                          message=(\n                              \"A rollback of changes performed by convert2rhel failed. The system is in an undefined state. \"\n                              \"Recover the system from a backup or contact Red Hat support.\"\n                          ),\n                          report=(\n                              \"\\nFor details, refer to the convert2rhel log file on the host at \"\n                              \"/var/log/convert2rhel/convert2rhel.log. Relevant lines from log file: \\n%s\\n\"\n                          )\n                          % rollback_errors,\n                      )\n\n                  step = \"pre-conversion analysis\" if IS_ANALYSIS else \"conversion\"\n                  raise ProcessError(\n                      message=(\n                          \"An error occurred during the %s. For details, refer to \"\n                          \"the convert2rhel log file on the host at /var/log/convert2rhel/convert2rhel.log\"\n                      )\n                      % step,\n                      report=(\n                          \"convert2rhel exited with code %s.\\n\"\n                          \"Output of the failed command: %s\"\n                          % (returncode, stdout.rstrip(\"\\n\"))\n                      ),\n                  )\n\n              # Only call insights to update inventory on successful conversion.\n              if IS_CONVERSION:\n                  update_insights_inventory()\n\n              logger.info(\n                  \"Convert2RHEL %s script finished successfully!\", SCRIPT_TYPE.title()\n              )\n          except ProcessError as exception:\n              logger.error(exception.report)\n              output = OutputCollector(\n                  status=\"ERROR\",\n                  alert=True,\n                  error=False,\n                  message=exception.message,\n                  report=exception.report,\n              )\n          except Exception as exception:\n              logger.critical(str(exception))\n              output = OutputCollector(\n                  status=\"ERROR\",\n                  alert=True,\n                  error=False,\n                  message=\"An unexpected error occurred. Expand the row for more details.\",\n                  report=str(exception),\n              )\n          finally:\n              # Report file could be either the pre-conversion or post-conversion\n              # depending on the SCRIPT_TYPE and conversion status. For example:\n              #   - If the SCRIPT_TYPE is analysis, then we will always use pre-conversion report\n              #   - If the SCRIPT_TYPE is conversion, we gonna check the following:\n              #       - If the conversion was successful, use the post-conversion report\n              #       - Otherwise, we probably have the pre-conversion report, so let's use that.\n              json_report_file = C2R_PRE_REPORT_FILE\n              txt_report_file = C2R_PRE_REPORT_TXT_FILE\n              if IS_CONVERSION and not os.path.exists(C2R_PRE_REPORT_FILE):\n                  json_report_file = C2R_POST_REPORT_FILE\n                  txt_report_file = C2R_POST_REPORT_TXT_FILE\n\n              # Gather JSON report\n              data = gather_json_report(json_report_file)\n\n              if data:\n                  output.status = data.get(\"status\", None)\n\n                  if not rollback_errors:\n                      # At this point we know JSON report exists and no rollback errors occured\n                      # we can rewrite previous conversion message with more specific one (or add missing message)\n                      # and set alert\n                      output.message, output.alert = generate_report_message(output.status)\n\n                  is_successful_conversion = IS_CONVERSION and execution_successful\n\n                  if is_successful_conversion:\n                      gpg_key_file.keep = True\n\n                      # NOTE: When c2r statistics on insights are not reliant on rpm being installed\n                      # remove below line (=decide only based on install_or_update_convert2rhel() result)\n                      if convert2rhel_installed:\n                          YUM_TRANSACTIONS_TO_UNDO.remove(transaction_id)\n\n                      # NOTE: Keep always because added/updated pkg is also kept\n                      # (if repo existed, the .backup file will remain on system)\n                      c2r_repo.keep = True\n\n                  should_attach_entries_and_report = (\n                      IS_CONVERSION or IS_ANALYSIS\n                  ) or not is_successful_conversion\n                  if not output.report and should_attach_entries_and_report:\n                      # Try to attach the textual report in the report if we have json\n                      # report, otherwise, we would overwrite the report raised by the\n                      # exception.\n                      output.report = gather_textual_report(txt_report_file)\n\n                  if not rollback_errors and should_attach_entries_and_report:\n                      output.entries = transform_raw_data(data)\n\n              if do_cleanup:\n                  cleanup(required_files)\n\n              print(\"### JSON START ###\")\n              print(json.dumps(output.to_dict(), indent=4))\n              print(\"### JSON END ###\")\n\n\n      def check_dist_version(dist, version):\n          \"\"\"Check for dist and version. If they don't match, raise an ProcessError and stop the script.\"\"\"\n          if dist and version:\n              is_valid_dist = dist.startswith(\"centos\")\n              is_valid_version = is_eligible_releases(version)\n              if not is_valid_dist or not is_valid_version:\n                  raise ProcessError(\n                      message=\"Conversion is only supported on CentOS 7.9 distributions.\",\n                      report='Exiting because distribution=\"%s\" and version=\"%s\"'\n                      % (dist.title(), version),\n                  )\n\n\n      if __name__ == \"__main__\":\n          main()\n    content_vars:\n      CONVERT2RHEL_THROUGH_INSIGHTS: 1\n      CONVERT2RHEL_CONFIGURE_HOST_METERING: auto\n      SCRIPT_MODE: CONVERSION\n      CONVERT2RHEL_ALLOW_UNAVAILABLE_KMODS: 0\n      CONVERT2RHEL_SKIP_KERNEL_CURRENCY_CHECK: 0\n      CONVERT2RHEL_OUTDATED_PACKAGE_CHECK_SKIP: 0\n      ELS_DISABLED: false\n# Multiple optional repository parameter values will be comma separated, for example:\n# rhel-7-server-optional-rpms,rhel-7-server-extras-rpms,rhel-7-server-supplementary-rpms\n      OPTIONAL_REPOSITORIES: None\n# Disable color for logging\n      NO_COLOR: 1\n",
      "active": true,
      "type": "S",
      "filters": [
        "centos",
        "os_v7"
      ],
      "filter_message": "Eligible systems for this task include CentOS systems that are registered via RHC"
    }
  },
  {
    "model": "tasks.Task",
    "pk": 10001,
    "fields": {
      "slug": "hello_world_script",
      "title": "Test invocation of a bash script via rhc-worker-script",
      "description": "Allows end-to-end test of Tasks executing a script via rhc-worker-script",
      "publish_date": "2023-8-03T00:00:00Z",
      "playbook": "# A simple bash script that Tasks can execute with rhc-worker-script\n- name: rhc-worker-script Hello World\n  vars:\n    insights_signature: !!binary |\n      TFMwdExTMUNSVWRKVGlCUVIxQWdVMGxIVGtGVVZWSkZMUzB0TFMwS1ZtVnljMmx2YmpvZ1IyNTFV\n      RWNnZGpFS0NtbFJTV05DUVVGQ1EwRkJSMEpSU20xaFlsTTVRVUZ2U2tWTmRuYzFPRVFyYWpWd1Rt\n      aHlWVkFyZDJWd05HZzFVa3cxT0U5TFRVTldiR3RzY2tSdmVVY0tVbkpoYWxOeVl6Vm1UekJQY25W\n      MVFuQnlhRGxIV2tZNWFURkxObkpPTUd0TFRrSkhXV3RFYTJNd2JIbG5lRUpxYUVKd1prZGhNa1po\n      VWtZNGJISjJNUXBPWlVGc1RXOXlUMXBJVldwa1RYWlNXRUk1TkZad01XOW1WM1J5UW5VMGJXbG5i\n      alYzWm5GRWRVVmtaV3cyYkdnellVSlZjU3R4TDNWSlRYRTRaMXBrQ2twQ2RuRXpkRnBwSzNSTlkx\n      UlNlWFpOUjNwcE5HODFhVzVZY0M5WGNFRnZOMjFNV0RacWRXMXVWVzVTTjFSMWEwTjNWVFE0YWxw\n      UFVYWkZPV0pOVVdVS1dGTTVOVEZOTlUxa1VWVmtWVWMzZDI1aGMxaHdOa3h1TDNGWE5uaGFNQ3Mx\n      YXpkTVp6Vm1UMVo0ZERZNVMyVkRWSFpvZFRobmJHeElSWE12YVhBelJRbzBURlJ2VTFocFZrWkxi\n      V2R6TkRCUGFHMHhObU5vSzBwbFJraFhZa1ZTUm01cldub3ZNR0V5YVhwbk5GcExkRzVFVlU1eGVr\n      ZFdabVJtVW5sWGEzaFRDbkFyVEVNeWNVbE1OWGg1UVU1WFoyOHhNalJQUkVONlkxbHRWaXRYUW01\n      dFV6QjBVblJKYkZoaVV6QmhjbFJyT1hGU2F5dDRjazg0Ym5kRk0wNVBaelVLTXlzNGRWSlpUVEZR\n      WWpGRGEwUjBVMHR1TTBkSE16WkpVR05MVWtWRVpUVnhiamgzSzA1R2VHWm9iak5DT0Vzd015OURO\n      RUpGZGpobE5reFZWeXRZUWdvclpUSnFjbTltWmpSTWIxRnJNRE5LY210eWRreFBXbXBGZDNkNFMy\n      ZzFhSEo0TUM4eGNrcENaM1ptWkdveU5WWTJkRkV3ZEZoMVJXcGFTRXhvTWpaSUNrUlVWRlZJTWta\n      TU9VZGpRaXRqUldsWll6aGtjbmhwTW5RMVZEZHhVV2w0Vms5cE9WUlRhWFpHYkZSVmVqWTFTeTlu\n      TUhCcllWZHVPRlIyVFZGUlpFOEtkbms0WW10dlVEUXlZVkEyZVZkWWJWSndSa1pIUTBaNVJHOHdV\n      MDFIVTFGa1pTdFNlbmhwUlVoTE1YUk9kemc1UmxVdllVeHJjWGhJWlZsS2RVbEpaZ3BxWTNGcFkw\n      ODFVbkY0VjFSWlZreFFNMnRvVFFvOWVWYzVkUW90TFMwdExVVk9SQ0JRUjFBZ1UwbEhUa0ZVVlZK\n      RkxTMHRMUzBL\n    insights_signature_exclude: /vars/insights_signature,/vars/content_vars\n    interpreter: /bin/bash\n    content: |\n      #!/bin/bash\n      cat << EOF\n      Hello World Script\n\n      ### JSON START ###\n      {\n        \"alert\": false,\n        \"message\": \"Hello World rhc-worker-script\",\n        \"report\": \"Data from env var: ${RHC_WORKER_TEST_VAR}\",\n        \"report_json\": { \"data\": \"structured data\" },\n        \"error\": false\n      }\n      ### JSON END ###\n\n      EOF\n    content_vars:\n      TEST_VAR: Hello World Env Var\n",
      "active": false,
      "type": "S",
      "filters": [
        "os_v7"
      ],
      "filter_message": "Eligible systems for this task include RHEL 7 and CentOS 7 systems that are registered via RHC"
    }
  },
  {
    "model": "tasks.Task",
    "pk": 7,
    "fields": {
      "slug": "bootc-upgrade",
      "title": "Initiate update of image mode for RHEL host",
      "description": "Use this Insights task to initiate an update of your image mode hosts.  Hosts will check their container repository for a new container image, upgrade themselves to that image, and perform the bootc upgrade function to convert the bootc image into an updated RHEL operating system.  Once updated, you will be able to view the new image associated with your hosts in Insights inventory.",
      "publish_date": "2024-04-25T00:00:00Z",
      "playbook": "- name: bootc upgrade\n  hosts: localhost\n  become: true\n  gather_facts: false\n  vars:\n    insights_signature_exclude: /hosts,/vars/insights_signature\n    insights_signature: !!binary |\n      TFMwdExTMUNSVWRKVGlCUVIxQWdVMGxIVGtGVVZWSkZMUzB0TFMwS1ZtVnljMmx2YmpvZ1IyNTFV\n      RWNnZGpFS0NtbFJTV05DUVVGQ1EwRkJSMEpSU205SVNsWjRRVUZ2U2tWTmRuYzFPRVFyYWpWd1Ru\n      VnVZMUZCUzBoS2RTdG9RMDVCVTFWNFF6STROM1ZVZG5FeGFHNEtlVVl6WjFZd1pISmtWbGRYVFV3\n      NVpVNTZabEZFVEN0NmVrdElaa1JoYzFsMlMyNVpSV3N6VVUxcWFUbFVTVXd2Y21GMk4yNXdTMWhF\n      V1VKRGVVSnVTZ3BhTlZCeFVXUmhZakk1ZEZaSFNqUnNXVXBvUlVGc1VsWm5RaTgzV2k4MVZGY3pV\n      emRUVDA5Mk5UUklRbFZDUzFsa0wzQTVORGh2TTNsVlVXOVJkVTVUQ2sxUFVHTXlWbFY2UlRaNVZX\n      dExXVFUwYUZjemJsbHlWMjkwWlRrMFN6TmlRVzFtUWxsb1RsWTJkR000TWtSUkswTTRTREJRTDNG\n      c1dFMVBiVVpvWXpBS1N6bEdjVU14Y1VsellVOWxUMnRGVm1KelpYSjZlQ3RCUnpoM2VFeFBkbGQz\n      Ym5VclUzRmlNbXBLT0hsVVRHTjJSRlozYm1vclFUTnplbk15VG1GT1dBcFhLMDE0Ym1KVVMwUjFT\n      MmcxWTFOTFlrTXJWVWt3ZW1oYVRXTnVkbkUzVTNCdlkweDJUV2M0UVZCWlRsTkZNVGhTY201V2Fp\n      OWhaR1JyUkdseWVIRmxDa1JEWlRablFYZE1RMkZUWVVSUU0waDNWR1ZqYkVKTk5HbDNjbVExYkRo\n      QmRIcHdSbkUwTW1kQmMwNVhWVzkxUW5CQ1pqVnNZakFyTVdGbmJtNUdVbmtLWlhWRk9VZHdNV1o0\n      TlRGemVqRlpRamhJVDFONlJtaHpiMll2ZDBkRVFVZEZlR1ZNVTBoSWFYRXlUMWhYSzNkRk56SjJX\n      V04zUVdGNFEwcGFlR2xQUmdvMmJISnFkU3RVVlhONllqaE1ialJsV1hCWk1EWlBSelZJYUV4bU5s\n      aENXVVJRYkdGTFRGUllhVUZhU213M1RrUmpibmhzWlUxc1ltMTROakpHZDNOR0NtSjVielZHU2pO\n      dlNHUnBNMGh3YVVOVmNubENVRE01YlRkbFJVbFFiV3AzV0RKa1lVaEVaM1JxYWtabFUyVjZhRWh3\n      T0UxUWMzQTJPRFJNZFRFNUsxQUtNMHR2YlRWa2RTdHlTMU5rTVdwalpuZFpaVkZ4VkdGS1JEQnJT\n      VmhJYVV4S05WcDRRMGQwV0ZJNFZIcERjM1pCTDB0NlUxTXZialpHVERGYWIzbFBiZ3BDV21WUFdX\n      cG9TRFpwVjNkTVVtOVNVMUpqZEFvOVRDODRaUW90TFMwdExVVk9SQ0JRUjFBZ1UwbEhUa0ZVVlZK\n      RkxTMHRMUzBL\n  tasks:\n    - name: Run bootc status to determine bootc image\n      ansible.builtin.shell: \"(bootc status --format=json 2>/dev/null || bootc status --json) | jq -r '.status.booted.image.image.image // .spec.image.image'\"\n      register: bootc_status_results\n    - name: Using bootc image from bootc status output {{bootc_status_results.stdout}}\n      ansible.builtin.set_fact:\n        bootc_image: \"{{bootc_status_results.stdout}}\"\n\n    - name: Execute bootc upgrade\n      ansible.builtin.shell: \"NO_COLOR=1 bootc upgrade 2>&1\"\n      register: command_results\n      no_log: true\n      ignore_errors: true\n\n    - block:\n        - when: \"command_results.rc != 0 or 'Queued for next boot' not in command_results.stdout\"\n          name: Set result for bootc upgrade failure\n          ansible.builtin.set_fact:\n            task_results:\n              report: \"{{command_results.stdout}}\\n{{command_results.stderr}}\"\n              message: \"bootc upgrade failed.  Expand for details.\"\n              alert: \"{{command_results.rc != 0}}\"\n\n        - name: Fail playbook if bootc upgrade failed\n          ansible.builtin.fail:\n            msg: \"bootc upgrade failed somehow.  Ensure the playbook fails as well.\"\n          when: task_results is defined\n\n        - when: task_results is not defined\n          name: Set result for bootc upgrade successful completion\n          ansible.builtin.set_fact:\n            task_results:\n              report: \"\"\n              message: \"bootc upgrade of '{{bootc_image}}' completed successfully.\"\n              alert: false\n\n        - when: \"'Queued for next boot' in command_results.stdout\"\n          block:\n            - name: Schedule insights-client after boot\n              file:\n                path: \"/etc/insights-client/.run_insights_client_next_boot\"\n                state: touch\n            - name: Enable boot service\n              systemd:\n                name: insights-client-boot.service\n                enabled: true\n              ignore_errors: true\n            - name: Reboot system\n              shell: sleep 10 && shutdown -r now \"Ansible triggered reboot\" &\n              ignore_errors: true\n\n      always:\n        - name: Print Task Result\n          ansible.builtin.debug:\n            var: task_results\n",
      "active": true,
      "type": "A",
      "filters": [
        "bootc_image",
        "not_rhelai_image"
      ],
      "filter_message": "Systems installed using bootc images are eligible for this task"
    }
  }, {
    "model": "tasks.Task",
    "pk": 8,
    "fields": {
      "slug": "rhel-ai-update",
      "title": "Initiate update of RHEL AI host",
      "description": "Use this task to initiate an update of your RHEL AI hosts.  You can update these hosts to different supported RHEL AI versions.  Once updated, you will be able to view the new image associated with your hosts in Insights inventory.  It is recommended to re-initialize your environment and configurations after you upgrade to the latest RHEL AI version.\n\n**Note:** You must be logged into the Red Hat Registry on each of the target hosts before running this task.  Also, the task may take a while to complete on each host.\n\nRefer to [Updating RHEL AI](https://docs.redhat.com/en/documentation/red_hat_enterprise_linux_ai/1.4/html-single/updating/index#updating_system) for more information.",
      "publish_date": "2025-03-25T00:00:00Z",
      "playbook": "- name: RHEL AI update\n  hosts: localhost\n  become: true\n  gather_facts: false\n  vars:\n    insights_signature_exclude: /hosts,/vars/insights_signature,/vars/content_vars\n    insights_signature: !!binary |\n      TFMwdExTMUNSVWRKVGlCUVIxQWdVMGxIVGtGVVZWSkZMUzB0TFMwS1ZtVnljMmx2YmpvZ1IyNTFV\n      RWNnZGpFS0NtbFJTV05DUVVGQ1EwRkJSMEpSU205SVNsWXJRVUZ2U2tWTmRuYzFPRVFyYWpWd1Rs\n      TjNaMUF2TVhWWVpGUjJTRTVTVHl0SFIzQjROelV3YW5KWlRGZ0tSSEkxUzI1V2EyVnljMGxHUkc4\n      elR6TllhV3RYZG5WRmIyZzJSWGxYVkRGdGJTODRWVzVLUWxsRmJWYzJPSFJTY0RsWFFuaGpkMUZM\n      TkdzMFFrVk1jQW8yVVZGT2RXeDBaVkJRYW1SSGNHRkpSVmw1YlhNNVIxZ3dNRUl3WXl0REswdFpl\n      bEZ4UjBFNVQxQlRWVzV6WldwVUsxaDVNbk0zY0RGTGQya3pNVk0xQ200d1IybE9kRzl0VG1aNWEz\n      ZHNWa0ptZFRaeGVXZHZTbEJ6YkRCeFNHeHlXbHBTYTA1UmQzRkhiRFp3ZEZOWllUQnJjbkp5YzBj\n      eVRVSlpUMUEzWmxVS1pteGtiRkoxUlZWaU5sVkhWVnBYV1ZsbVltOXhWWE4zUzNCQ2ExUkVTbEZ2\n      YW1KU1YzWlZVSGMwZGtwM1NIQnFhQ3QwU1RORmRHTnBWekF5YjIwMFJncG1iR2xwYlV0YWNIaEdN\n      WGhKZFZwTGFHRlVZblZUZHpVd1YxQndhakpxYUdKQ1EwZFhXVTVhYjJzNGJHZHlkemhRYWpWcmVE\n      QllXbkJZTlhWeWMzcDNDaXRrZEd0TGFGRkpkRUprZEVWNlMzZFJZVE5xT0cxQlNsVnVWMDgxVEho\n      clZ6aGtZWFJGT1RWVVlqSk1SMXBDZDJaNGQxQjZXbGhMVDBkRlV6Rk1aV1lLVjFaSlpuSm9PVWs1\n      YkRCNkwyVkZZWEp0YjBacWIxZHZXRkpEZDNKNWQyeGxOVEkwVVV4UWR5dHVkWGd3Y1hBdmRrRlJT\n      bTVCYzJkelNtNUtkWE5SWlFwdlJFaDNTbTlUYkdWc01URjBRMlZRWm1oRE4zb3pXbk0xZUV0MlNG\n      ZGFXbUlyZVZGMFdrdE5hekJsY1dSSE4zbExkWFJzTW5BNVVsRnJOSFJOTWk5dENrTkdjR1Y0UjNa\n      aU0ySjRiVzkzVDB4T1IySkpPQzlqVWxsR1FXczRVa055WlZSaGJrbzNiWGhuTUhObU9WSkNUa2x1\n      Ym5SSk5qbHFaRU5pVEZaMmFXd0thbFoyV1ZCM1dISjVRMnR5ZVRKRlJHVnlkRzl6Y1VweGIzSTVP\n      VFU0WTJGUVVUa3hhR3RDU0ZGaFpuUmFWbFJtZFRKbmRtaElaRGxCVUZCaFEwOTJZd3AxYVdrMFNs\n      Y3lUa2hMT1ZKYWJXOTVhREYxVXdvOVdHSkpZZ290TFMwdExVVk9SQ0JRUjFBZ1UwbEhUa0ZVVlZK\n      RkxTMHRMUzBL\n    content_vars:\n      update_version: \"z-stream\"\n\n  tasks:\n    - name: Run bootc status to determine Red Hat container registry and RHEL AI image\n      ansible.builtin.shell: \"(bootc status --format=json 2>/dev/null || bootc status --json) | jq -r '.status.booted.image.image.image // .spec.image.image'\"\n      register: bootc_status_results\n    - name: Using RHEL AI image from bootc status output {{bootc_status_results.stdout}}\n      ansible.builtin.set_fact:\n        rhelai_image: \"{{bootc_status_results.stdout}}\"\n    - name: Extract Red Hat container registry name from {{rhelai_image}}\n      ansible.builtin.set_fact:\n        rh_registry: \"{{rhelai_image | split('/') | first}}\"\n\n    - when: content_vars.update_version in ['z-stream', 'latest']\n      name: Use bootc upgrade command to update image\n      ansible.builtin.set_fact:\n        bootc_command: \"bootc upgrade\"\n\n    - when: content_vars.update_version not in ['z-stream', 'latest']\n      block:\n        - name: Extract RHEL AI image name from {{rhelai_image}}\n          ansible.builtin.set_fact:\n            rhelai_image_name: \"{{rhelai_image | regex_replace(':([^:]+)$', '')}}\"\n        - name: Set new RHEL AI image with update_version tag\n          ansible.builtin.set_fact:\n            new_rhelai_image: \"{{rhelai_image_name}}:{{content_vars.update_version}}\"\n        - name: Use bootc switch command to update image {{new_rhelai_image}}\n          ansible.builtin.set_fact:\n            bootc_command: \"bootc switch {{new_rhelai_image}}\"\n\n    - name: Execute '{{bootc_command}}'\n      ansible.builtin.shell: \"NO_COLOR=1 {{bootc_command}} 2>&1\"\n      register: bootc_command_results\n      no_log: true\n      ignore_errors: true\n\n    - block:\n        - when: \"bootc_command_results.rc != 0 and 'unauthorized' in bootc_command_results.stdout\"\n          name: Set result for '{{bootc_command}}' authorization failure\n          ansible.builtin.set_fact:\n            task_results:\n              report: \"{{bootc_command_results.stdout}}\\n{{bootc_command_results.stderr}}\"\n              message: \"Accessing Red Hat Container Registry failed.  Run 'podman login {{rh_registry}} --authfile=/etc/ostree/auth.json' on the target system.\"\n              alert: false\n\n        - when: \"task_results is not defined and (bootc_command_results.rc != 0 or 'Queued for next boot' not in bootc_command_results.stdout)\"\n          name: Set result for '{{bootc_command}}' failure\n          ansible.builtin.set_fact:\n            task_results:\n              report: \"{{bootc_command_results.stdout}}\\n{{bootc_command_results.stderr}}\"\n              message: \"RHEL AI image update failed.  Expand for details.\"\n              alert: \"{{bootc_command_results.rc != 0}}\"\n\n        - name: Fail playbook if RHEL AI update failed\n          ansible.builtin.fail:\n            msg: \"RHEL AI image update failed somehow.  Ensure the playbook fails as well.\"\n          when: task_results is defined\n\n        - when: task_results is not defined\n          name: Set result for '{{bootc_command}}' successful completion\n          ansible.builtin.set_fact:\n            task_results:\n              report: \"\"\n              message: \"RHEL AI image update to '{{new_rhelai_image | default(rhelai_image, true)}}' completed successfully.\"\n              alert: false\n\n        - when: \"'Queued for next boot' in bootc_command_results.stdout\"\n          block:\n            - name: Schedule insights-client after boot\n              file:\n                path: \"/etc/insights-client/.run_insights_client_next_boot\"\n                state: touch\n            - name: Enable boot service\n              systemd:\n                name: insights-client-boot.service\n                enabled: true\n              ignore_errors: true\n            - name: Reboot system\n              shell: sleep 10 && shutdown -r now \"Ansible triggered reboot\" &\n              ignore_errors: true\n\n      always:\n        - name: Print Task Result\n          ansible.builtin.debug:\n            var: task_results\n",
      "active": true,
      "type": "A",
      "filters": [
        "bootc_image",
        "rhelai_image"
      ],
      "filter_message": "Systems installed using RHEL AI images are eligible for this task"
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 10001,
    "fields": {
      "task_id": 10001,
      "key": "TEST_VAR",
      "title": "Script Parameter",
      "description": "Parameter to pass to the script",
      "values": [
        "Hello World Env Var",
        "OMG it works",
        "Mark rocks",
        "STOP. Hammer Time"
      ],
      "default": "Hello World Env Var",
      "required": true,
      "multi_valued": true,
      "index": 1
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1020,
    "fields": {
      "task_id": 2,
      "key": "collector",
      "title": "Collector",
      "description": "Run the specified app and upload its results archive",
      "values": [
          "None",
          "malware-detection"
      ],
      "default": "None",
      "required": false,
      "multi_valued": false,
      "index": 1
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1021,
    "fields": {
      "task_id": 2,
      "key": "show_results",
      "title": "Show results",
      "description": "Show insights about this host",
      "values": [
          "True",
          "False"
      ],
      "default": "False",
      "required": false,
      "multi_valued": false,
      "index": 2
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1022,
    "fields": {
      "task_id": 2,
        "key": "status",
        "title": "Status",
        "description": "Check this machine's registration status with Red Hat Insights",
        "values": [
            "True",
            "False"
        ],
        "default": "False",
        "required": false,
        "multi_valued": false,
        "index": 3
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1023,
    "fields": {
      "task_id": 2,
      "key": "test_connection",
      "title": "Test connection",
      "description": "Test connectivity to Red Hat",
      "values": [
          "True",
          "False"
      ],
      "default": "False",
      "required": false,
      "multi_valued": false,
      "index": 4
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1024,
    "fields": {
      "task_id": 2,
      "key": "verbose",
      "title": "Verbose",
      "description": "Run insights-client with verbose output",
      "values": [
          "True",
          "False"
      ],
      "default": "False",
      "required": false,
      "multi_valued": false,
      "index": 5
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1025,
    "fields": {
      "task_id": 2,
      "key": "keep_archive",
      "title": "Keep archive",
      "description": "Store archive in /var/cache/insights-client/ after upload",
      "values": [
          "True",
          "False"
      ],
      "default": "False",
      "required": false,
      "multi_valued": false,
      "index": 6
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1040,
    "fields": {
      "task_id": 4,
      "key": "ELS_DISABLED",
      "title": "Do not use the ELS subscription.",
      "description": "If you plan to upgrade to RHEL 8 right after the conversion, you may opt not to use the ELS subscription. Note that the conversion and the subsequent upgrade without an ELS subscription come with a limited support scope per the Convert2RHEL Support Policy and the In-place upgrade Support Policy.",
      "values": [
        "True",
        "False"
      ],
      "default": "False",
      "required": true,
      "multi_valued": false,
      "index": 1
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1041,
    "fields": {
      "task_id": 4,
      "key": "CONVERT2RHEL_ALLOW_UNAVAILABLE_KMODS",
      "title": "Allow loaded kernel modules unavailable in RHEL repositories",
      "description": "We cannot guarantee that the loaded kernel modules reported by the pre-conversion analysis as not available in RHEL repositories will function properly with a RHEL kernel after the conversion. We recommend you to unload the modules by following How do I prevent a kernel module from loading automatically?, perform the conversion without the modules loaded and verify they work upon loading them after the conversion.  Using this option is equivalent to setting the CONVERT2RHEL_ALLOW_UNAVAILABLE_KMODS environment variable on the command line.",
      "values": [
        "1",
        "0"
      ],
      "default": "0",
      "required": true,
      "multi_valued": false,
      "index": 2
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1042,
    "fields": {
      "task_id": 4,
      "key": "CONVERT2RHEL_SKIP_KERNEL_CURRENCY_CHECK",
      "title": "Allow outdated kernel on the system",
      "description": "We test the conversions with the latest available kernel so rather than using this option we recommend updating the kernel to its latest available version with a subsequent system reboot to prevent conversion issues.  Using this option is equivalent to setting the CONVERT2RHEL_SKIP_KERNEL_CURRENCY_CHECK environment variable on the command line.",
      "values": [
        "1",
        "0"
      ],
      "default": "0",
      "required": true,
      "multi_valued": false,
      "index": 3
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1043,
    "fields": {
      "task_id": 4,
      "key": "CONVERT2RHEL_OUTDATED_PACKAGE_CHECK_SKIP",
      "title": "Allow outdated packages on the system",
      "description": "We test the conversions with the latest available package versions so rather than using this option we recommend updating the installed packages to their latest available version to prevent conversion issues.  Using this option is equivalent to setting the CONVERT2RHEL_OUTDATED_PACKAGE_CHECK_SKIP environment variable on the command line.",
      "values": [
        "1",
        "0"
      ],
      "default": "0",
      "required": true,
      "multi_valued": false,
      "index": 4
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1044,
    "fields": {
      "task_id": 4,
      "key": "CONVERT2RHEL_TAINTED_KERNEL_MODULE_CHECK_SKIP",
      "title": "Allow tainted kernel modules",
      "description": "Tainted kernel modules present a potential source of conversion issues. We recommend you to unload the modules by following How do I prevent a kernel module from loading automatically? Use this option if you cannot do so.  Using this option is equivalent to setting the CONVERT2RHEL_TAINTED_KERNEL_MODULE_CHECK_SKIP environment variable on the command line.",
      "values": [
        "1",
        "0"
      ],
      "default": "0",
      "required": true,
      "multi_valued": false,
      "index": 5
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1045,
    "fields": {
      "task_id": 4,
      "key": "OPTIONAL_REPOSITORIES",
      "title": "Enable non-default RHEL repositories.",
      "description": "Allow the installed CentOS packages to be converted to RHEL packages from the below non-default repositories. By default only those CentOS packages that are available in the default rhel-7-server-rpms repository will be converted.",
      "values": [
          "None",
          "rhel-7-server-optional-rpms",
          "rhel-7-server-extras-rpms",
          "rhel-7-server-supplementary-rpms"
      ],
      "default": "None",
      "required": true,
      "multi_valued": true,
      "index": 6
}
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1060,
    "fields": {
      "task_id": 6,
      "key": "ELS_DISABLED",
      "title": "Do not use the ELS subscription.",
      "description": "If you plan to upgrade to RHEL 8 right after the conversion, you may opt not to use the ELS subscription. Note that the conversion and the subsequent upgrade without an ELS subscription come with a limited support scope per the Convert2RHEL Support Policy and the In-place upgrade Support Policy.",
      "values": [
        "True",
        "False"
      ],
      "default": "False",
      "required": true,
      "multi_valued": false,
      "index": 1
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1061,
    "fields": {
      "task_id": 6,
      "key": "CONVERT2RHEL_ALLOW_UNAVAILABLE_KMODS",
      "title": "Allow loaded kernel modules unavailable in RHEL repositories",
      "description": "We cannot guarantee that the loaded kernel modules reported by the pre-conversion analysis as not available in RHEL repositories will function properly with a RHEL kernel after the conversion. We recommend you to unload the modules by following How do I prevent a kernel module from loading automatically?, perform the conversion without the modules loaded and verify they work upon loading them after the conversion.  Using this option is equivalent to setting the CONVERT2RHEL_ALLOW_UNAVAILABLE_KMODS environment variable on the command line.",
      "values": [
        "1",
        "0"
      ],
      "default": "0",
      "required": true,
      "multi_valued": false,
      "index": 2
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1062,
    "fields": {
      "task_id": 6,
      "key": "CONVERT2RHEL_SKIP_KERNEL_CURRENCY_CHECK",
      "title": "Allow outdated kernel on the system",
      "description": "We test the conversions with the latest available kernel so rather than using this option we recommend updating the kernel to its latest available version with a subsequent system reboot to prevent conversion issues.  Using this option is equivalent to setting the CONVERT2RHEL_SKIP_KERNEL_CURRENCY_CHECK environment variable on the command line.",
      "values": [
        "1",
        "0"
      ],
      "default": "0",
      "required": true,
      "multi_valued": false,
      "index": 3
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1063,
    "fields": {
      "task_id": 6,
      "key": "CONVERT2RHEL_OUTDATED_PACKAGE_CHECK_SKIP",
      "title": "Allow outdated packages on the system",
      "description": "We test the conversions with the latest available package versions so rather than using this option we recommend updating the installed packages to their latest available version to prevent conversion issues.  Using this option is equivalent to setting the CONVERT2RHEL_OUTDATED_PACKAGE_CHECK_SKIP environment variable on the command line.",
      "values": [
        "1",
        "0"
      ],
      "default": "0",
      "required": true,
      "multi_valued": false,
      "index": 4
    }
  }, {
    "model": "tasks.TaskParameter",
    "pk": 1064,
    "fields": {
      "task_id": 6,
      "key": "CONVERT2RHEL_TAINTED_KERNEL_MODULE_CHECK_SKIP",
      "title": "Allow tainted kernel modules",
      "description": "Tainted kernel modules present a potential source of conversion issues. We recommend you to unload the modules by following How do I prevent a kernel module from loading automatically? Use this option if you cannot do so.  Using this option is equivalent to setting the CONVERT2RHEL_TAINTED_KERNEL_MODULE_CHECK_SKIP environment variable on the command line.",
      "values": [
        "1",
        "0"
      ],
      "default": "0",
      "required": true,
      "multi_valued": false,
      "index": 5
    }
  },
  {
    "model": "tasks.TaskParameter",
    "pk": 1065,
    "fields": {
      "task_id": 6,
      "key": "OPTIONAL_REPOSITORIES",
      "title": "Enable non-default RHEL repositories.",
      "description": "Allow the installed CentOS packages to be converted to RHEL packages from the below non-default repositories. By default only those CentOS packages that are available in the default rhel-7-server-rpms repository will be converted.",
      "values": [
        "None",
        "rhel-7-server-optional-rpms",
        "rhel-7-server-extras-rpms",
        "rhel-7-server-supplementary-rpms"
      ],
      "default": "None",
      "required": true,
      "multi_valued": true,
      "index": 6
    }
  },
  {
    "model": "tasks.TaskParameter",
    "pk": 1080,
    "fields": {
      "task_id": 8,
      "key": "update_version",
      "title": "Update version",
      "description": "Update RHEL AI host image to this version",
      "values": [
        "1.5",
        "1.4",
        "z-stream"
      ],
      "default": "1.5",
      "required": true,
      "multi_valued": false,
      "index": 1
    }
  }
]
